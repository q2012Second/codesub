This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: src/codesub/models.py, src/codesub/detector.py, src/codesub/cli.py, src/codesub/api.py, src/codesub/config_store.py, src/codesub/git_repo.py, src/codesub/errors.py, tasks/semantic_subscriptions_research.md, tasks/semantic/review.md, tasks/semantic-subscriptions/plan.md, tasks/semantic-subscriptions/plan-review.md, research/semantic-code-parsing.md
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
research/
  semantic-code-parsing.md
src/
  codesub/
    api.py
    cli.py
    config_store.py
    detector.py
    errors.py
    git_repo.py
    models.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="research/semantic-code-parsing.md">
# Semantic Code Parsing and Tracking - Research Findings

> Last researched: 2026-01-26
> Focus: Approaches for parsing code constructs and tracking them across git commits

## Executive Summary

This research evaluates approaches for **semantic code parsing** and **tracking code constructs** (classes, functions, variables) across git changes. The goal is to support a tool that can:
- Parse Python code to find class/function/variable definitions
- Track the same construct across git commits (even if moved/renamed)
- Eventually support Java and Go

### Key Findings

1. **Tree-sitter** is the best option for multi-language parsing with excellent performance
2. **Python AST** is simplest for Python-only use cases but has limitations
3. **LibCST** excels at code transformation but is Python-only
4. **GumTree** and semantic diff tools struggle with cross-file tracking
5. **RefactoringMiner** is the gold standard for tracking refactorings across files (Java-focused)
6. **LSIF** is designed for IDE navigation, not historical tracking

---

## 1. Tree-sitter

### Overview
Tree-sitter is an **incremental parsing library** that generates concrete syntax trees (CST) for multiple programming languages. Originally created for text editors, it's now widely used in static analysis tools including GitHub's code navigation.

### Python Bindings

**Installation:**
```bash
pip install tree-sitter
pip install tree-sitter-python  # For Python support
pip install tree-sitter-languages  # Pre-built grammars for 50+ languages
```

**Key Libraries:**
- `py-tree-sitter` - Official Python bindings (v0.25.2 as of 2026)
- `tree-sitter-languages` - Pre-compiled language grammars
- Individual packages: `tree-sitter-python`, `tree-sitter-java`, `tree-sitter-go`

### Query Syntax for Finding Code Constructs

Tree-sitter uses a Lisp-style query language with pattern matching:

```python
from tree_sitter import Parser, Language
import tree_sitter_python as tspython

# Setup
PY_LANGUAGE = Language(tspython.language())
parser = Parser(PY_LANGUAGE)

# Find function definitions
query = PY_LANGUAGE.query("""
(function_definition
  name: (identifier) @function.name
  parameters: (parameters) @function.params
  body: (block) @function.body)
""")

# Find class definitions
class_query = PY_LANGUAGE.query("""
(class_definition
  name: (identifier) @class.name
  body: (block) @class.body)
""")

# Find variable assignments
var_query = PY_LANGUAGE.query("""
(assignment
  left: (identifier) @var.name
  right: (_) @var.value)
""")

# Parse and query
tree = parser.parse(bytes(code, "utf8"))
captures = query.captures(tree.root_node)
```

**Query Features:**
- Field names for precise matching (e.g., `name:`, `body:`)
- Capture groups using `@capture.name` syntax
- Wildcard matching with `(_)`
- Predicate filtering for complex conditions

### Multi-Language Support

Tree-sitter provides **50+ language grammars** including:
- Python, Java, Go, JavaScript, TypeScript, Rust, C/C++
- Single interface for all languages
- Language-agnostic query patterns

**Language-specific setup:**
```python
import tree_sitter_java
import tree_sitter_go

JAVA_LANGUAGE = Language(tree_sitter_java.language())
GO_LANGUAGE = Language(tree_sitter_go.language())
```

### Performance Characteristics

- **Incremental parsing**: O(n) parsing, updates in <1ms for typical edits
- **10x faster** than regex-based syntax highlighting
- **Efficient tree diffing**: `Tree.changed_ranges()` identifies modified regions
- **Memory efficient**: Pre-compiled language binaries, no runtime dependencies
- **Java parsing speedup**: One project saw 36x improvement over JavaParser

### APIs

**Core Classes:**
- `Parser` - Configures language and parses source
- `Tree` - Root of parsed syntax tree
- `Node` - Individual syntax node with type, position, children
- `Query` - Pattern-based node searching
- `QueryCursor` - Executes queries and returns captures
- `TreeCursor` - Efficient tree traversal

**Node Operations:**
```python
node.type              # Node type (e.g., "function_definition")
node.text              # Source text as bytes
node.start_byte        # Starting byte position
node.end_byte          # Ending byte position
node.start_point       # (row, column) tuple
node.children          # Child nodes
node.child_by_field_name("name")  # Access named fields
```

**Incremental Parsing:**
```python
old_tree = parser.parse(old_code)
new_tree = parser.parse(new_code, old_tree=old_tree)  # Much faster!
changed_ranges = new_tree.changed_ranges(old_tree)
```

### Limitations

1. **TreeCursor limitation**: Can only traverse children of starting node (not full tree)
2. **Cross-file tracking**: Tree-sitter doesn't track code across files
3. **Rename detection**: No built-in support for detecting renames
4. **Requires old tree**: Incremental parsing needs previous tree state

### Use Cases for codesub

**Pros:**
‚úÖ Multi-language support (Python, Java, Go)
‚úÖ Extremely fast incremental parsing
‚úÖ Robust handling of syntax errors
‚úÖ Active development with strong ecosystem
‚úÖ Used in production by GitHub, Neovim, Emacs

**Cons:**
‚ùå No built-in rename/move detection
‚ùå Single-file focus (no cross-file awareness)
‚ùå Requires manual tracking of node identity across commits

**Recommendation:** Use tree-sitter for **parsing** code constructs, but implement custom logic for **tracking** constructs across commits using fingerprinting or similarity matching.

---

## 2. Python AST Module

### Overview
Python's built-in `ast` module parses Python source code into an Abstract Syntax Tree. It's lossy (discards formatting) but provides native Python integration.

### Capabilities

**Extracting Definitions:**
```python
import ast

class DefinitionVisitor(ast.NodeVisitor):
    def __init__(self):
        self.classes = []
        self.functions = []
        self.variables = []

    def visit_ClassDef(self, node):
        self.classes.append({
            'name': node.name,
            'lineno': node.lineno,
            'end_lineno': node.end_lineno
        })
        self.generic_visit(node)

    def visit_FunctionDef(self, node):
        self.functions.append({
            'name': node.name,
            'lineno': node.lineno,
            'end_lineno': node.end_lineno,
            'args': [arg.arg for arg in node.args.args]
        })
        self.generic_visit(node)

    def visit_Assign(self, node):
        for target in node.targets:
            if isinstance(target, ast.Name):
                self.variables.append({
                    'name': target.id,
                    'lineno': node.lineno
                })
        self.generic_visit(node)

# Usage
tree = ast.parse(source_code)
visitor = DefinitionVisitor()
visitor.visit(tree)
```

**Key Node Types:**
- `ast.ClassDef` - Class definitions
- `ast.FunctionDef` / `ast.AsyncFunctionDef` - Function definitions
- `ast.Assign` - Variable assignments
- `ast.Import` / `ast.ImportFrom` - Imports
- `ast.Call` - Function calls

### Limitations

1. **Stack depth crashes**: Malformed AST can crash Python interpreter (raises `RecursionError`, `MemoryError`, `ValueError`)
2. **Decorator complexity**: Decorators can be complex expressions (not just names), causing `AttributeError` if handled naively
3. **Missing source info**: If `lineno`, `end_lineno`, `col_offset` missing, `ast.get_source_segment()` returns `None`
4. **Python-only**: No support for other languages
5. **Lossy parsing**: Cannot reconstruct original source code (whitespace, comments lost)

### Performance

- **Fastest Python parser**: Native C implementation
- **Simple API**: Part of standard library, no dependencies
- **Good for analysis**: Excellent for linting, static analysis where formatting doesn't matter

### Use Cases for codesub

**Pros:**
‚úÖ Built-in, no dependencies
‚úÖ Fastest Python parsing
‚úÖ Simple API for basic analysis
‚úÖ Well-documented with extensive ecosystem

**Cons:**
‚ùå Python-only (no Java/Go support)
‚ùå Lossy (can't preserve formatting)
‚ùå Limited error recovery
‚ùå No rename/move detection

**Recommendation:** Use for **Python-only prototyping** or when multi-language support isn't needed. For production with Java/Go requirements, choose tree-sitter instead.

---

## 3. LibCST

### Overview
LibCST is a **lossless Concrete Syntax Tree** parser for Python that preserves all formatting details (whitespace, comments, parentheses). Created by Instagram, it's designed for automated code refactoring (codemods).

### What Makes LibCST Different

LibCST creates a compromise between AST and CST:
- **Lossless**: Preserves formatting, comments, whitespace
- **AST-like**: Organized around semantic meaning (not just syntax tokens)
- **Roundtrip**: Can parse ‚Üí modify ‚Üí print with formatting preserved

**Comparison:**

| Feature | Python AST | LibCST | Tree-sitter |
|---------|-----------|--------|-------------|
| Preserves formatting | ‚ùå | ‚úÖ | ‚úÖ |
| Python-only | ‚úÖ | ‚úÖ | ‚ùå (multi-lang) |
| Can modify code | ‚úÖ | ‚úÖ | ‚ùå (read-only) |
| Built-in | ‚úÖ | ‚ùå | ‚ùå |
| Speed | Fastest | Slower | Fast |

### When to Use LibCST

**Use LibCST when:**
- Building codemods (automated refactoring tools)
- Need to preserve code formatting and style
- Making semantic changes while maintaining original appearance
- Building Python linters with auto-fix capabilities

**Don't use LibCST when:**
- Building compilers or type checkers (use Python AST)
- Only reading code (not modifying)
- Need multi-language support (use tree-sitter)
- Performance is critical (use Python AST)

### APIs for Finding Constructs

**Installation:**
```bash
pip install libcst
```

**Visitor Pattern:**
```python
import libcst as cst

class CodeAnalyzer(cst.CSTVisitor):
    def __init__(self):
        self.classes = []
        self.functions = []
        self.stack = []  # Track nesting

    def visit_ClassDef(self, node: cst.ClassDef) -> None:
        self.classes.append(node.name.value)
        self.stack.append(node.name.value)

    def leave_ClassDef(self, node: cst.ClassDef) -> None:
        self.stack.pop()

    def visit_FunctionDef(self, node: cst.FunctionDef) -> None:
        qualified_name = ".".join(self.stack + [node.name.value])
        self.functions.append(qualified_name)
        return False  # Don't traverse into function body

# Usage
module = cst.parse_module(source_code)
visitor = CodeAnalyzer()
module.visit(visitor)
```

**Transformer Pattern (for modifications):**
```python
class FunctionRenamer(cst.CSTTransformer):
    def leave_FunctionDef(
        self, original: cst.FunctionDef, updated: cst.FunctionDef
    ) -> cst.FunctionDef:
        if original.name.value == "old_name":
            return updated.with_changes(
                name=cst.Name("new_name")
            )
        return updated

# Apply transformation
new_module = module.visit(FunctionRenamer())
print(new_module.code)  # Prints modified code with formatting preserved
```

**Metadata Providers:**
- `PositionProvider` - Line/column information
- `ScopeProvider` - Variable scope analysis
- `QualifiedNameProvider` - Fully qualified names for imports

### Performance

- **Slower than Python AST**: Extra work to track whitespace
- **Production-ready**: Used at Instagram scale
- **Python 3.9+ required**
- No benchmarks available, but acceptable for most use cases

### Limitations

1. **Python-only**: No support for Java, Go, or other languages
2. **Slower parsing**: More overhead than Python AST
3. **Rust toolchain**: Required for building on unsupported platforms
4. **No cross-file tracking**: Single file focus like other parsers

### Use Cases for codesub

**Pros:**
‚úÖ Perfect for code transformation tools
‚úÖ Preserves formatting (useful for applying fixes)
‚úÖ Rich metadata support
‚úÖ Production-tested at Instagram

**Cons:**
‚ùå Python-only (no Java/Go support)
‚ùå Slower than alternatives
‚ùå No built-in rename/move detection
‚ùå Overkill if only reading code

**Recommendation:** Use LibCST if codesub needs to **apply automated fixes** to Python subscriptions. Otherwise, tree-sitter is better for multi-language support.

---

## 4. GumTree and Semantic Diff Tools

### GumTree

**Overview:**
GumTree is an AST-based diff tool that computes differences at the syntax tree level rather than text level. It can detect moved or renamed elements beyond simple insertions/deletions.

### How It Works

GumTree performs tree-to-tree differencing using:
1. **AST construction** for both versions
2. **Tree matching** to find corresponding nodes
3. **Edit script generation** with syntax-aware actions

**6 Edit Actions:**
1. Insert a node
2. Delete a node
3. Update a node label (e.g., rename)
4. Move a subtree
5. Insert a subtree
6. Delete a subtree

### Supported Languages

- C, Java, JavaScript, Python, R, Ruby
- Uses multiple generator approaches:
  - `gen.jdt` - Eclipse JDT for Java
  - `gen.javaparser` - JavaParser for Java
  - `gen.treesitter-ng` - Tree-sitter for various languages
  - `gen.antlr3` - ANTLR for custom grammars

### Rename Detection

**How renames are shown:**
Renamed identifiers appear as "Update a node label" actions:
```
Update((identifier:my_func, line 1:12 - 1:19), new_func_name)
```

**Limitation:** If matching fails, GumTree may forcefully match deleted methods to added methods, misleading reviewers into thinking methods were renamed when they weren't.

### Critical Limitations

1. **No cross-file detection**: GumTree accepts pairs of files as input and "cannot detect the move of a code fragment to another file modified in the same commit"
2. **Per-file matching**: Forces matching within single files, missing cross-file refactorings
3. **Incorrect matching**: Can produce misleading diffs when similarity is low

**Exception:** **Staged Tree Matching** extension applies GumTree across multiple files in a commit, addressing the cross-file limitation.

### CLI Usage

```bash
# Install
git clone https://github.com/GumTreeDiff/gumtree
cd gumtree
./gradlew build

# Run diff
./gumtree-*/bin/gumtree textdiff old_file.py new_file.py

# Web UI
./gumtree-*/bin/gumtree webdiff old_file.py new_file.py
```

### Related Tools

**diffsitter** (tree-sitter based):
- Creates semantic diffs using tree-sitter parsers
- Ignores formatting differences (whitespace, optional punctuation)
- Filters nodes via `include_nodes` / `exclude_nodes` config
- Uses LCS (Longest Common Subsequence) on AST leaves

**Installation:**
```bash
cargo install diffsitter
```

**Limitations:**
- Language support limited to tree-sitter parsers
- Node filtering only applies to leaf nodes
- Output not significantly more readable than traditional diff
- No high-level refactoring detection (e.g., "Extract Method")

**code-diff** (Python library):
- Fast reimplementation of GumTree algorithm
- Detects function renames in Python, Java, JavaScript
- Uses tree-sitter for parsing

```python
import code_diff as cd
output = cd.difference(source_code, target_code, lang="python")
print(output.edit_script())
```

**Example output:**
```
Update((identifier:my_func, line 1:12 - 1:19), say_helloworld)
```

**astdiff** (Basic Python tool):
- Compares ASTs and returns 0 if same, 1 if different
- Can check commits or working trees
- Much simpler than GumTree, no rename detection

### Use Cases for codesub

**Pros:**
‚úÖ Syntax-aware diffing (ignores formatting)
‚úÖ Detects moves and renames within files
‚úÖ Multi-language support
‚úÖ Well-researched algorithm

**Cons:**
‚ùå No cross-file tracking (critical limitation)
‚ùå Single-file pairs only (standard version)
‚ùå Incorrect matching when similarity is low
‚ùå Requires external process (Java-based)
‚ùå No built-in git integration

**Recommendation:** GumTree is **not suitable** for codesub's use case. It cannot track code moved between files in a commit. Consider **RefactoringMiner** instead (see next section).

---

## 5. RefactoringMiner

### Overview
RefactoringMiner is a research tool that detects refactorings in git commits with **cross-file awareness**. Unlike GumTree, it analyzes all modified files in a commit together, enabling detection of methods moved between files.

### Key Capabilities

**Refactoring Detection:**
- Rename Method, Move Method
- Rename Class, Move Class, Move and Rename Class
- Extract and Move Method
- Pull Up/Push Down Method
- Inline/Extract Method
- Change Method Signature

**Cross-File Awareness:**
Unlike GumTree and other AST diff tools, RefactoringMiner is "aware of changes taking place in other files modified in the same commit." This enables detection of:
- Methods moved to different files
- Classes renamed and moved
- Code extracted from one file and moved to another

### Technical Approach

RefactoringMiner uses a **threshold-free matching approach**:
- Applies all syntactically valid AST node replacements
- Matches statements only if they become textually identical after replacements
- More precise than similarity-based matching (avoids false positives)

**Advantages:**
- Automatically excludes files with identical contents
- Shows overlapping refactorings within moved code
- Can generate diffs for any pair of modified/added/deleted files

### Installation & Requirements

**Requirements:**
- Java 17 or newer (since v3.0.0)
- Gradle 7.4 or newer

**Installation:**
```bash
git clone https://github.com/tsantalis/RefactoringMiner
cd RefactoringMiner
./gradlew build
```

### Usage

**CLI:**
```bash
# Analyze a commit
./gradlew run -Pargs="-c /path/to/repo commit-sha"

# Analyze a range of commits
./gradlew run -Pargs="-bc /path/to/repo commit1 commit2"

# Analyze all commits
./gradlew run -Pargs="-a /path/to/repo branch"
```

**API (Java):**
```java
GitService gitService = new GitServiceImpl();
GitHistoryRefactoringMiner miner = new GitHistoryRefactoringMinerImpl();

miner.detectAtCommit(repository, commitId, new RefactoringHandler() {
    @Override
    public void handle(String commitId, List<Refactoring> refactorings) {
        for (Refactoring ref : refactorings) {
            System.out.println(ref.toString());
        }
    }
});
```

### Output Format

```json
{
  "commits": [
    {
      "sha1": "abc123",
      "refactorings": [
        {
          "type": "Move Method",
          "description": "Move Method calculateTotal() from class OrderService to class PriceCalculator",
          "leftSideLocations": [
            {
              "filePath": "src/OrderService.java",
              "startLine": 42,
              "endLine": 58
            }
          ],
          "rightSideLocations": [
            {
              "filePath": "src/PriceCalculator.java",
              "startLine": 15,
              "endLine": 31
            }
          ]
        }
      ]
    }
  ]
}
```

### Limitations

1. **Java-focused**: Primarily designed for Java (uses Eclipse JDT parser)
2. **Research tool**: Not production-ready for continuous integration
3. **Performance**: Can be slow on large repositories with many commits
4. **Language support**: Limited to languages with mature AST parsers (mainly Java)
5. **Git-only**: Requires git repository structure

### Use Cases for codesub

**Pros:**
‚úÖ **Cross-file tracking** (critical for codesub)
‚úÖ Detects renamed and moved methods
‚úÖ Git-integrated (works with commits)
‚úÖ Threshold-free matching (precise)
‚úÖ Production-tested in research

**Cons:**
‚ùå Java-focused (limited Python/Go support)
‚ùå Research tool (may lack polish)
‚ùå Performance concerns on large repos
‚ùå Requires Java runtime

**Recommendation:** RefactoringMiner's approach is **ideal for codesub**, but it's Java-focused. Consider implementing a **similar cross-file approach** using tree-sitter for Python/Java/Go support.

---

## 6. LSIF (Language Server Index Format)

### Overview
LSIF is a **graph-based format** for storing language server knowledge, enabling rich code navigation (Go to Definition, Find References) without local source code or running a language server.

### Purpose

LSIF is designed for:
- Code browsing in web UIs (GitHub, GitLab)
- Pull request review with code navigation
- Static code analysis without compilation
- IDE-like features in non-IDE environments

### How It Works

**Graph Structure:**
- **Vertices**: Documents, code ranges, hover info, definition results
- **Edges**: Relationships (containment, references, definitions)

**Example data:**
```json
{"id": 1, "type": "vertex", "label": "document", "uri": "file:///path/to/file.py"}
{"id": 2, "type": "vertex", "label": "range", "start": {"line": 5, "character": 4}}
{"id": 3, "type": "edge", "label": "contains", "outV": 1, "inV": 2}
```

### Indexed Data

LSIF supports:
- Document symbols and folding ranges
- Hover information (type, documentation)
- Go to Definition/Declaration/Type Definition
- Find All References
- Go to Implementation
- Document links

**Note:** LSIF "doesn't contain any program symbol information" in the sense that it models LSP request results, not semantic analysis.

### Available Tools

**Generators:**
- `lsif-java` - Java indexer (Microsoft)
- `lsif-node` - TypeScript/JavaScript indexer
- `lsif-go` - Go indexer
- Various community indexers for Python, C++, etc.

**Consumers:**
- VS Code extension for LSIF
- Sourcegraph code intelligence
- GitHub code navigation

### Limitations for Code Tracking

1. **Point-in-time**: LSIF indexes a single workspace snapshot, not history
2. **No cross-commit tracking**: Not designed for tracking code evolution
3. **Static navigation**: Enables "Go to Definition" but not "Track this function across commits"
4. **Large file size**: Complete LSIF dumps can be gigabytes for large projects

### Use Cases for codesub

**Pros:**
‚úÖ Multi-language support (via LSP)
‚úÖ Standardized format
‚úÖ Rich semantic information

**Cons:**
‚ùå **Not designed for history tracking**
‚ùå Point-in-time snapshots only
‚ùå Large file sizes
‚ùå Complex graph format
‚ùå Requires language-specific indexers

**Recommendation:** LSIF is **not suitable** for codesub. It's designed for code navigation, not tracking constructs across commits.

---

## 7. Additional Approaches

### Code Fingerprinting / Semantic Hashing

**Concept:** Generate stable hashes of code constructs based on semantic features, enabling tracking across renames and minor modifications.

**Techniques:**

1. **Syntax Tree Fingerprinting:**
   - Hash AST structure (node types, relationships)
   - Normalize identifier names (e.g., replace with placeholders)
   - Creates fingerprints stable across renames

2. **Semantic Hashing (for binaries):**
   - Extract control flow graphs (CFG)
   - Hash instruction sequences
   - Used in BinSign, semantic_firewall projects

3. **Locality-Sensitive Hashing (LSH):**
   - Hash similar code to similar values
   - Enables approximate matching
   - Used for clone detection

**Example Approach:**
```python
import hashlib
import ast

def fingerprint_function(func_node: ast.FunctionDef) -> str:
    """Generate semantic fingerprint for a function."""
    # Extract structural features
    features = {
        'num_params': len(func_node.args.args),
        'num_statements': len(func_node.body),
        'calls': [n.func.id for n in ast.walk(func_node)
                  if isinstance(n, ast.Call) and isinstance(n.func, ast.Name)],
        'control_flow': count_control_structures(func_node)
    }

    # Hash normalized features
    feature_string = str(sorted(features.items()))
    return hashlib.sha256(feature_string.encode()).hexdigest()
```

**Tools:**
- `semantic_firewall` (Go) - Fingerprints Go functions using SSA analysis
- Research papers on syntax tree fingerprinting
- Clone detection tools (e.g., SourcererCC, CCFinderX)

**Use Case for codesub:**

Fingerprinting could enable tracking functions across commits:
1. Parse code at each commit using tree-sitter
2. Generate fingerprint for each function/class
3. Match fingerprints across commits
4. Detect moved/renamed constructs by fingerprint similarity

**Pros:**
‚úÖ Detects renames (name not included in fingerprint)
‚úÖ Robust to minor modifications
‚úÖ Works across files

**Cons:**
‚ùå False positives (similar code, different purpose)
‚ùå False negatives (significant refactoring changes fingerprint)
‚ùå Requires tuning similarity thresholds
‚ùå No standard library/tool

### Git's Built-in Rename Detection

Git has rename detection via `git diff -M` and `git log --follow`:

```bash
# Detect renames in diff
git diff -M HEAD~1 HEAD

# Follow file history across renames
git log --follow -- path/to/file.py
```

**How it works:**
- Hashes file content
- Detects files with >50% similarity (configurable)
- Works at file level, not function level

**Limitations:**
- File-level only (not function/class level)
- No cross-file detection for extracted code
- Similarity-based (can miss semantic renames)

---

## Recommendations for codesub

### Parsing Approach

**Use Tree-sitter** for parsing code constructs:

**Rationale:**
1. ‚úÖ Multi-language support (Python, Java, Go)
2. ‚úÖ Fast incremental parsing
3. ‚úÖ Robust error handling
4. ‚úÖ Active development, strong ecosystem
5. ‚úÖ Used in production by GitHub, major editors

**Implementation:**
```python
from tree_sitter import Parser, Language
import tree_sitter_python, tree_sitter_java, tree_sitter_go

LANGUAGES = {
    'python': Language(tree_sitter_python.language()),
    'java': Language(tree_sitter_java.language()),
    'go': Language(tree_sitter_go.language())
}

def parse_file(file_path: str, language: str):
    parser = Parser(LANGUAGES[language])
    with open(file_path, 'rb') as f:
        code = f.read()
    return parser.parse(code)

def find_functions(tree, language: str):
    """Extract function definitions from tree."""
    query_patterns = {
        'python': '(function_definition name: (identifier) @name)',
        'java': '(method_declaration name: (identifier) @name)',
        'go': '(function_declaration name: (identifier) @name)'
    }

    query = LANGUAGES[language].query(query_patterns[language])
    captures = query.captures(tree.root_node)
    return [node.text.decode('utf8') for name, node in captures]
```

### Tracking Approach

**Implement a hybrid approach** combining:

1. **Tree-sitter for parsing** at each git commit
2. **Semantic fingerprinting** for matching constructs across commits
3. **Cross-file awareness** (analyze all modified files together like RefactoringMiner)
4. **Git diff context** for detecting file renames

**Architecture:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Subscription Manager                        ‚îÇ
‚îÇ - Subscriptions stored with fingerprints    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Change Detector (per commit)                ‚îÇ
‚îÇ 1. Get modified files (git diff --name-only)‚îÇ
‚îÇ 2. Parse old & new versions (tree-sitter)   ‚îÇ
‚îÇ 3. Extract constructs (functions, classes)  ‚îÇ
‚îÇ 4. Generate fingerprints                    ‚îÇ
‚îÇ 5. Match across files                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Subscription Updater                        ‚îÇ
‚îÇ - Match fingerprints to subscriptions       ‚îÇ
‚îÇ - Update line ranges                        ‚îÇ
‚îÇ - Flag moved/renamed constructs             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Fingerprinting Strategy:**

For Python functions:
```python
def fingerprint_function(node, source_code):
    """Generate semantic fingerprint for function."""
    features = {
        'num_params': count_parameters(node),
        'num_statements': count_statements(node),
        'return_type': extract_return_type(node),
        'called_functions': extract_function_calls(node),
        'control_structures': count_control_structures(node),
        'body_hash': hash_normalized_body(node)  # Normalize variable names
    }
    return hash(frozenset(features.items()))
```

For Java methods:
```python
def fingerprint_method(node, source_code):
    """Generate semantic fingerprint for Java method."""
    features = {
        'signature_hash': hash_signature(node),  # Types, not names
        'num_statements': count_statements(node),
        'method_calls': extract_method_calls(node),
        'field_accesses': extract_field_accesses(node),
        'control_flow_hash': hash_control_flow(node)
    }
    return hash(frozenset(features.items()))
```

**Matching Algorithm:**

```python
def match_constructs(old_constructs, new_constructs, threshold=0.85):
    """Match constructs across commits using fingerprints."""
    matches = []

    for old_construct in old_constructs:
        best_match = None
        best_similarity = 0

        for new_construct in new_constructs:
            similarity = compute_similarity(
                old_construct.fingerprint,
                new_construct.fingerprint
            )

            if similarity > best_similarity:
                best_similarity = similarity
                best_match = new_construct

        if best_similarity >= threshold:
            matches.append((old_construct, best_match, best_similarity))

    return matches
```

### Implementation Phases

**Phase 1: Basic Tree-sitter Integration**
- Parse Python files using tree-sitter
- Extract function/class definitions
- Store construct metadata with subscriptions

**Phase 2: Fingerprinting**
- Implement semantic fingerprinting
- Test on real refactoring examples
- Tune similarity thresholds

**Phase 3: Cross-File Tracking**
- Analyze all modified files in a commit together
- Match constructs across files
- Detect moved/renamed constructs

**Phase 4: Multi-Language**
- Add Java support (tree-sitter-java)
- Add Go support (tree-sitter-go)
- Generalize fingerprinting approach

---

## Summary Table

| Approach | Multi-Lang | Cross-File | Rename Detection | Performance | Recommendation |
|----------|-----------|------------|------------------|-------------|----------------|
| **Tree-sitter** | ‚úÖ Yes | ‚ùå No | ‚ùå No | ‚ö° Excellent | **Use for parsing** |
| **Python AST** | ‚ùå Python-only | ‚ùå No | ‚ùå No | ‚ö°‚ö° Best | Prototype only |
| **LibCST** | ‚ùå Python-only | ‚ùå No | ‚ùå No | üêå Slower | Use for codemods |
| **GumTree** | ‚úÖ Yes | ‚ùå No | ‚ö†Ô∏è Partial | ‚ö° Good | Not suitable |
| **RefactoringMiner** | ‚ö†Ô∏è Java-focused | ‚úÖ Yes | ‚úÖ Yes | üêå Slow | Learn from approach |
| **LSIF** | ‚úÖ Yes | ‚ùå No | ‚ùå No | ‚ö° Good | Not for tracking |
| **Fingerprinting** | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes | ‚ö° Good | **Use for tracking** |

**Final Recommendation:**
- **Parse with tree-sitter** (multi-language, fast, robust)
- **Track with semantic fingerprinting** (cross-file, rename detection)
- **Inspire approach from RefactoringMiner** (cross-file awareness)
- **Start with Python, expand to Java/Go** (incremental implementation)

---

## Sources

### Tree-sitter
- [py-tree-sitter GitHub](https://github.com/tree-sitter/py-tree-sitter)
- [Query Documentation](https://tree-sitter.github.io/py-tree-sitter/classes/tree_sitter.Query.html)
- [tree-sitter-languages PyPI](https://pypi.org/project/tree-sitter-languages/)
- [Diving into Tree-Sitter Tutorial](https://dev.to/shrsv/diving-into-tree-sitter-parsing-code-with-python-like-a-pro-17h8)
- [Tree-sitter Official Docs](https://tree-sitter.github.io/)
- [TreeSitter Parsing Blog](https://symflower.com/en/company/blog/2023/parsing-code-with-tree-sitter/)

### Python AST & LibCST
- [Python AST Documentation](https://docs.python.org/3/library/ast.html)
- [LibCST GitHub](https://github.com/Instagram/LibCST)
- [LibCST Documentation](https://libcst.readthedocs.io/)
- [Why LibCST?](https://libcst.readthedocs.io/en/latest/why_libcst.html)
- [LibCST Tutorial](https://libcst.readthedocs.io/en/latest/tutorial.html)

### GumTree & Semantic Diff
- [GumTree GitHub](https://github.com/GumTreeDiff/gumtree)
- [diffsitter GitHub](https://github.com/afnanenayet/diffsitter)
- [code-diff GitHub](https://github.com/cedricrupb/code_diff)
- [astdiff PyPI](https://pypi.org/project/astdiff/)
- [Semantic Code Diff Review](https://mgx.dev/insights/a-comprehensive-review-of-semantic-code-diff-analysis-from-foundations-to-future-trends/f78dabc3a2394fb18d57f3e8736acbb7)
- [Novel Refactoring AST Tool (PDF)](https://users.encs.concordia.ca/~nikolaos/publications/TOSEM_2024.pdf)

### RefactoringMiner
- [RefactoringMiner GitHub](https://github.com/tsantalis/RefactoringMiner)
- [Tracking Java Methods with Git (PDF)](https://arxiv.org/pdf/2003.05336)

### LSIF
- [LSIF Overview](https://microsoft.github.io/language-server-protocol/overviews/lsif/overview/)
- [LSIF Specification 0.5.0](https://microsoft.github.io/language-server-protocol/specifications/lsif/0.5.0/specification/)
- [LSIF Blog Post](https://code.visualstudio.com/blogs/2019/02/19/lsif)

### Code Fingerprinting
- [semantic_firewall GitHub](https://github.com/BlackVectorOps/semantic_firewall)
- [Binary Code Fingerprinting Survey](https://dl.acm.org/doi/10.1145/3486860)
- [Syntax Tree Fingerprinting Paper](https://www.researchgate.net/publication/221219530_Syntax_tree_fingerprinting_for_source_code_similarity_detection)

### Comparisons
- [Tree-sitter vs LSP](https://byteiota.com/tree-sitter-vs-lsp-why-hybrid-ide-architecture-wins/)
- [code_ast GitHub](https://github.com/cedricrupb/code_ast)
</file>

<file path="src/codesub/config_store.py">
"""Configuration storage for codesub."""

import json
import os
import tempfile
from pathlib import Path
from typing import Any

from .errors import (
    ConfigExistsError,
    ConfigNotFoundError,
    InvalidSchemaVersionError,
    SubscriptionNotFoundError,
)
from .models import Config, Subscription, _utc_now

SCHEMA_VERSION = 1
CONFIG_DIR = ".codesub"
CONFIG_FILE = "subscriptions.json"
UPDATE_DOCS_DIR = "last_update_docs"


class ConfigStore:
    """Manages reading and writing the subscription configuration."""

    def __init__(self, repo_root: Path):
        """
        Initialize ConfigStore.

        Args:
            repo_root: Path to the repository root directory.
        """
        self.repo_root = repo_root
        self.config_dir = repo_root / CONFIG_DIR
        self.config_path = self.config_dir / CONFIG_FILE
        self.update_docs_dir = self.config_dir / UPDATE_DOCS_DIR

    def exists(self) -> bool:
        """Check if config file exists."""
        return self.config_path.exists()

    def load(self) -> Config:
        """
        Load configuration from disk.

        Raises:
            ConfigNotFoundError: If config doesn't exist.
            InvalidSchemaVersionError: If schema version is unsupported.
        """
        if not self.exists():
            raise ConfigNotFoundError(str(self.config_path))

        with open(self.config_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        version = data.get("schema_version", 0)
        if version != SCHEMA_VERSION:
            raise InvalidSchemaVersionError(version, SCHEMA_VERSION)

        return Config.from_dict(data)

    def save(self, config: Config) -> None:
        """
        Save configuration to disk atomically.

        Uses write-to-temp-then-rename for atomicity.
        """
        # Ensure config directory exists
        self.config_dir.mkdir(parents=True, exist_ok=True)

        # Update the updated_at timestamp
        config.repo.updated_at = _utc_now()

        # Write to temp file then rename (atomic on POSIX)
        data = config.to_dict()
        fd, temp_path = tempfile.mkstemp(
            dir=self.config_dir, prefix=".subscriptions_", suffix=".tmp"
        )
        try:
            with os.fdopen(fd, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2)
                f.write("\n")  # trailing newline
            os.replace(temp_path, self.config_path)
        except Exception:
            # Clean up temp file on failure (ignore errors if already removed)
            try:
                os.unlink(temp_path)
            except OSError:
                pass
            raise

    def init(self, baseline_ref: str, force: bool = False) -> Config:
        """
        Initialize a new configuration.

        Args:
            baseline_ref: The baseline git ref (usually HEAD).
            force: If True, overwrite existing config.

        Returns:
            The created Config.

        Raises:
            ConfigExistsError: If config exists and force=False.
        """
        if self.exists() and not force:
            raise ConfigExistsError(str(self.config_path))

        config = Config.create(baseline_ref)
        self.save(config)

        # Create update docs directory
        self.update_docs_dir.mkdir(parents=True, exist_ok=True)

        return config

    def add_subscription(self, sub: Subscription) -> None:
        """Add a subscription to the config."""
        config = self.load()
        config.subscriptions.append(sub)
        self.save(config)

    def list_subscriptions(self, include_inactive: bool = False) -> list[Subscription]:
        """
        List all subscriptions.

        Args:
            include_inactive: If True, include inactive subscriptions.
        """
        config = self.load()
        if include_inactive:
            return config.subscriptions
        return [s for s in config.subscriptions if s.active]

    def get_subscription(self, sub_id: str) -> Subscription:
        """
        Get a subscription by ID (supports partial ID matching).

        Raises:
            SubscriptionNotFoundError: If subscription doesn't exist.
        """
        config = self.load()
        matches = [s for s in config.subscriptions if s.id.startswith(sub_id)]

        if not matches:
            raise SubscriptionNotFoundError(sub_id)
        if len(matches) > 1:
            raise SubscriptionNotFoundError(
                f"{sub_id} (ambiguous, matches {len(matches)} subscriptions)"
            )

        return matches[0]

    def remove_subscription(self, sub_id: str, hard: bool = False) -> Subscription:
        """
        Remove or deactivate a subscription.

        Args:
            sub_id: Subscription ID (or prefix).
            hard: If True, delete entirely. If False, set active=False.

        Returns:
            The removed/deactivated subscription.

        Raises:
            SubscriptionNotFoundError: If subscription doesn't exist.
        """
        config = self.load()
        matches = [(i, s) for i, s in enumerate(config.subscriptions) if s.id.startswith(sub_id)]

        if not matches:
            raise SubscriptionNotFoundError(sub_id)
        if len(matches) > 1:
            raise SubscriptionNotFoundError(
                f"{sub_id} (ambiguous, matches {len(matches)} subscriptions)"
            )

        idx, sub = matches[0]

        if hard:
            config.subscriptions.pop(idx)
        else:
            sub.active = False
            sub.updated_at = _utc_now()

        self.save(config)
        return sub

    def update_subscription(self, sub: Subscription) -> None:
        """
        Update an existing subscription.

        Raises:
            SubscriptionNotFoundError: If subscription doesn't exist.
        """
        config = self.load()
        for i, existing in enumerate(config.subscriptions):
            if existing.id == sub.id:
                sub.updated_at = _utc_now()
                config.subscriptions[i] = sub
                self.save(config)
                return

        raise SubscriptionNotFoundError(sub.id)

    def update_baseline(self, new_ref: str) -> None:
        """Update the baseline ref."""
        config = self.load()
        config.repo.baseline_ref = new_ref
        self.save(config)

    def get_baseline(self) -> str:
        """Get the current baseline ref."""
        config = self.load()
        return config.repo.baseline_ref
</file>

<file path="src/codesub/api.py">
"""FastAPI REST API for codesub subscription management."""

from fastapi import FastAPI, HTTPException, Query, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import Optional

from .config_store import ConfigStore
from .errors import (
    CodesubError,
    ConfigNotFoundError,
    SubscriptionNotFoundError,
    InvalidLocationError,
    InvalidLineRangeError,
    FileNotFoundAtRefError,
    InvalidSchemaVersionError,
    NotAGitRepoError,
    GitError,
    ProjectNotFoundError,
    InvalidProjectPathError,
    ScanNotFoundError,
)
from .git_repo import GitRepo
from .models import Anchor, Subscription
from .utils import parse_location, extract_anchors
from .project_store import ProjectStore
from .scan_history import ScanHistory
from .detector import Detector
from .updater import Updater
from .update_doc import result_to_dict


# --- Pydantic Schemas ---


class AnchorSchema(BaseModel):
    context_before: list[str]
    lines: list[str]
    context_after: list[str]


class SubscriptionSchema(BaseModel):
    id: str
    path: str
    start_line: int
    end_line: int
    label: Optional[str] = None
    description: Optional[str] = None
    anchors: Optional[AnchorSchema] = None
    active: bool = True
    created_at: str
    updated_at: str


class SubscriptionCreateRequest(BaseModel):
    """Request body for creating a subscription."""

    location: str = Field(..., description="path:line or path:start-end format")
    label: Optional[str] = None
    description: Optional[str] = None
    context: int = Field(default=2, ge=0, le=10)


class SubscriptionUpdateRequest(BaseModel):
    """Request body for updating a subscription."""

    label: Optional[str] = None
    description: Optional[str] = None


class SubscriptionListResponse(BaseModel):
    subscriptions: list[SubscriptionSchema]
    count: int
    baseline_ref: str
    baseline_title: str = ""


class ErrorResponse(BaseModel):
    detail: str
    error_type: str


# --- Project Schemas ---


class ProjectSchema(BaseModel):
    id: str
    name: str
    path: str
    created_at: str
    updated_at: str


class ProjectCreateRequest(BaseModel):
    path: str = Field(..., description="Absolute path to git repository")
    name: Optional[str] = Field(None, description="Display name (defaults to dir name)")


class ProjectUpdateRequest(BaseModel):
    name: str = Field(..., description="New display name")


class ProjectListResponse(BaseModel):
    projects: list[ProjectSchema]
    count: int


class ProjectStatusResponse(BaseModel):
    project: ProjectSchema
    path_exists: bool
    codesub_initialized: bool
    subscription_count: int
    baseline_ref: Optional[str]


# --- Scan Schemas ---


class ScanRequest(BaseModel):
    base_ref: str = Field(..., description="Base git ref (e.g., 'HEAD~1', 'baseline', commit hash)")
    target_ref: Optional[str] = Field(default="HEAD", description="Target git ref ('HEAD', commit hash), or empty/null for working directory")


class TriggerSchema(BaseModel):
    subscription_id: str
    path: str
    start_line: int
    end_line: int
    reasons: list[str]
    label: Optional[str]


class ProposalSchema(BaseModel):
    subscription_id: str
    old_path: str
    old_start: int
    old_end: int
    new_path: str
    new_start: int
    new_end: int
    reasons: list[str]
    confidence: str
    shift: Optional[int]
    label: Optional[str]


class ScanResultSchema(BaseModel):
    base_ref: str
    target_ref: str
    triggers: list[TriggerSchema]
    proposals: list[ProposalSchema]
    unchanged_count: int


class ScanHistoryEntrySchema(BaseModel):
    id: str
    project_id: str
    base_ref: str
    target_ref: str
    trigger_count: int
    proposal_count: int
    unchanged_count: int
    created_at: str


class ScanHistoryListResponse(BaseModel):
    scans: list[ScanHistoryEntrySchema]
    count: int


class ApplyUpdatesRequest(BaseModel):
    scan_id: str = Field(..., description="Scan ID to apply proposals from")
    proposal_ids: Optional[list[str]] = Field(
        None,
        description="Specific proposal IDs to apply (all if not specified)"
    )


class ApplyUpdatesResponse(BaseModel):
    applied: list[str]
    warnings: list[str]
    new_baseline: Optional[str]


# --- Helper Functions ---


def get_project_store() -> ProjectStore:
    """Get the global ProjectStore."""
    return ProjectStore()


def get_scan_history() -> ScanHistory:
    """Get the global ScanHistory."""
    return ScanHistory()


def get_project_store_and_repo(project_id: str) -> tuple[ConfigStore, GitRepo]:
    """Get ConfigStore and GitRepo for a specific project."""
    project_store = get_project_store()
    project = project_store.get_project(project_id)

    repo = GitRepo(project.path)
    store = ConfigStore(repo.root)
    return store, repo


def get_store_and_repo() -> tuple[ConfigStore, GitRepo]:
    """Get ConfigStore and GitRepo for the current directory."""
    repo = GitRepo()
    store = ConfigStore(repo.root)
    return store, repo


def subscription_to_schema(sub: Subscription) -> SubscriptionSchema:
    """Convert dataclass Subscription to Pydantic schema."""
    anchors = None
    if sub.anchors:
        anchors = AnchorSchema(
            context_before=sub.anchors.context_before,
            lines=sub.anchors.lines,
            context_after=sub.anchors.context_after,
        )
    return SubscriptionSchema(
        id=sub.id,
        path=sub.path,
        start_line=sub.start_line,
        end_line=sub.end_line,
        label=sub.label,
        description=sub.description,
        anchors=anchors,
        active=sub.active,
        created_at=sub.created_at,
        updated_at=sub.updated_at,
    )


# --- FastAPI App ---


app = FastAPI(
    title="codesub API",
    description="REST API for managing code subscriptions",
    version="0.1.0",
)

# CORS for local development
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- Global Exception Handler ---


# Map exception types to HTTP status codes
ERROR_STATUS_CODES: dict[type, int] = {
    ConfigNotFoundError: 409,
    SubscriptionNotFoundError: 404,
    InvalidLocationError: 400,
    InvalidLineRangeError: 400,
    FileNotFoundAtRefError: 404,
    InvalidSchemaVersionError: 500,
    NotAGitRepoError: 500,
    GitError: 500,
    ProjectNotFoundError: 404,
    InvalidProjectPathError: 400,
    ScanNotFoundError: 404,
}


@app.exception_handler(CodesubError)
async def codesub_error_handler(request: Request, exc: CodesubError) -> JSONResponse:
    """Map CodesubError subclasses to appropriate HTTP responses."""
    status_code = ERROR_STATUS_CODES.get(type(exc), 500)
    return JSONResponse(
        status_code=status_code,
        content={"detail": str(exc), "error_type": type(exc).__name__},
    )


# --- Endpoints ---


@app.get("/api/subscriptions", response_model=SubscriptionListResponse)
def list_subscriptions(include_inactive: bool = Query(default=False)):
    """List all subscriptions, optionally including inactive ones."""
    store, repo = get_store_and_repo()
    config = store.load()
    subs = store.list_subscriptions(include_inactive=include_inactive)
    baseline_title = repo.commit_title(config.repo.baseline_ref) if config.repo.baseline_ref else ""
    return SubscriptionListResponse(
        subscriptions=[subscription_to_schema(s) for s in subs],
        count=len(subs),
        baseline_ref=config.repo.baseline_ref,
        baseline_title=baseline_title,
    )


@app.get("/api/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def get_subscription(sub_id: str):
    """Get a single subscription by ID (supports partial ID matching)."""
    store, _ = get_store_and_repo()
    sub = store.get_subscription(sub_id)
    return subscription_to_schema(sub)


@app.post("/api/subscriptions", response_model=SubscriptionSchema, status_code=201)
def create_subscription(request: SubscriptionCreateRequest):
    """Create a new subscription."""
    store, repo = get_store_and_repo()
    config = store.load()

    # Parse and validate location
    path, start_line, end_line = parse_location(request.location)

    # Validate file exists at baseline
    baseline = config.repo.baseline_ref
    lines = repo.show_file(baseline, path)

    # Validate line range
    if end_line > len(lines):
        raise InvalidLineRangeError(
            start_line, end_line, f"exceeds file length ({len(lines)} lines)"
        )

    # Extract anchors
    context_before, watched_lines, context_after = extract_anchors(
        lines, start_line, end_line, context=request.context
    )
    anchors = Anchor(
        context_before=context_before,
        lines=watched_lines,
        context_after=context_after,
    )

    # Create subscription
    sub = Subscription.create(
        path=path,
        start_line=start_line,
        end_line=end_line,
        label=request.label,
        description=request.description,
        anchors=anchors,
    )

    store.add_subscription(sub)
    return subscription_to_schema(sub)


@app.patch("/api/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def update_subscription(sub_id: str, request: SubscriptionUpdateRequest):
    """Update subscription label and/or description.

    PATCH semantics:
    - Omitted field: keep existing value
    - Empty string "": clear to null
    - Explicit null: clear to null
    """
    store, _ = get_store_and_repo()
    sub = store.get_subscription(sub_id)

    # Get the fields that were actually sent in the request
    update_data = request.model_dump(exclude_unset=True)

    # Update fields if provided
    if "label" in update_data:
        # Empty string becomes None
        sub.label = request.label if request.label else None
    if "description" in update_data:
        # Empty string becomes None
        sub.description = request.description if request.description else None

    store.update_subscription(sub)
    return subscription_to_schema(sub)


@app.delete("/api/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def delete_subscription(sub_id: str, hard: bool = Query(default=False)):
    """Delete (deactivate or hard delete) a subscription."""
    store, _ = get_store_and_repo()
    sub = store.remove_subscription(sub_id, hard=hard)
    return subscription_to_schema(sub)


@app.post("/api/subscriptions/{sub_id}/reactivate", response_model=SubscriptionSchema)
def reactivate_subscription(sub_id: str):
    """Reactivate a deactivated subscription."""
    store, _ = get_store_and_repo()
    sub = store.get_subscription(sub_id)

    if sub.active:
        raise HTTPException(status_code=400, detail="Subscription is already active")

    sub.active = True
    store.update_subscription(sub)
    return subscription_to_schema(sub)


@app.get("/api/health")
def health_check():
    """Health check endpoint. Always returns 200."""
    try:
        store, repo = get_store_and_repo()
        config_exists = store.exists()
        baseline_ref = None
        if config_exists:
            config = store.load()
            baseline_ref = config.repo.baseline_ref
        return {
            "status": "ok",
            "config_initialized": config_exists,
            "repo_root": str(repo.root),
            "baseline_ref": baseline_ref,
        }
    except NotAGitRepoError:
        return {
            "status": "error",
            "config_initialized": False,
            "detail": "Not running in a git repository",
        }
    except Exception as e:
        return {
            "status": "error",
            "config_initialized": False,
            "detail": str(e),
        }


# --- Project Endpoints ---


@app.get("/api/projects", response_model=ProjectListResponse)
def list_projects():
    """List all registered projects."""
    store = get_project_store()
    projects = store.list_projects()
    return ProjectListResponse(
        projects=[ProjectSchema(**p.to_dict()) for p in projects],
        count=len(projects),
    )


@app.post("/api/projects", response_model=ProjectSchema, status_code=201)
def create_project(request: ProjectCreateRequest):
    """Register a new project."""
    store = get_project_store()
    project = store.add_project(path=request.path, name=request.name)
    return ProjectSchema(**project.to_dict())


@app.get("/api/projects/{project_id}", response_model=ProjectStatusResponse)
def get_project_status(project_id: str):
    """Get project details and status."""
    store = get_project_store()
    status = store.get_project_status(project_id)
    return ProjectStatusResponse(
        project=ProjectSchema(**status["project"]),
        path_exists=status["path_exists"],
        codesub_initialized=status["codesub_initialized"],
        subscription_count=status["subscription_count"],
        baseline_ref=status["baseline_ref"],
    )


@app.patch("/api/projects/{project_id}", response_model=ProjectSchema)
def update_project(project_id: str, request: ProjectUpdateRequest):
    """Update project name."""
    store = get_project_store()
    project = store.update_project(project_id, request.name)
    return ProjectSchema(**project.to_dict())


@app.delete("/api/projects/{project_id}", response_model=ProjectSchema)
def delete_project(project_id: str):
    """Remove a project from the registry."""
    store = get_project_store()
    project = store.remove_project(project_id)
    return ProjectSchema(**project.to_dict())


# --- Project Subscriptions Endpoints ---


@app.get("/api/projects/{project_id}/subscriptions", response_model=SubscriptionListResponse)
def list_project_subscriptions(
    project_id: str,
    include_inactive: bool = Query(default=False)
):
    """List subscriptions for a specific project."""
    store, repo = get_project_store_and_repo(project_id)
    config = store.load()
    subs = store.list_subscriptions(include_inactive=include_inactive)
    baseline_title = repo.commit_title(config.repo.baseline_ref) if config.repo.baseline_ref else ""
    return SubscriptionListResponse(
        subscriptions=[subscription_to_schema(s) for s in subs],
        count=len(subs),
        baseline_ref=config.repo.baseline_ref,
        baseline_title=baseline_title,
    )


@app.post("/api/projects/{project_id}/subscriptions", response_model=SubscriptionSchema, status_code=201)
def create_project_subscription(project_id: str, request: SubscriptionCreateRequest):
    """Create a new subscription in a specific project."""
    store, repo = get_project_store_and_repo(project_id)
    config = store.load()

    # Parse and validate location
    path, start_line, end_line = parse_location(request.location)

    # Validate file exists at baseline
    baseline = config.repo.baseline_ref
    lines = repo.show_file(baseline, path)

    # Validate line range
    if end_line > len(lines):
        raise InvalidLineRangeError(
            start_line, end_line, f"exceeds file length ({len(lines)} lines)"
        )

    # Extract anchors
    context_before, watched_lines, context_after = extract_anchors(
        lines, start_line, end_line, context=request.context
    )
    anchors = Anchor(
        context_before=context_before,
        lines=watched_lines,
        context_after=context_after,
    )

    # Create subscription
    sub = Subscription.create(
        path=path,
        start_line=start_line,
        end_line=end_line,
        label=request.label,
        description=request.description,
        anchors=anchors,
    )

    store.add_subscription(sub)
    return subscription_to_schema(sub)


@app.get("/api/projects/{project_id}/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def get_project_subscription(project_id: str, sub_id: str):
    """Get a single subscription by ID within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.get_subscription(sub_id)
    return subscription_to_schema(sub)


@app.patch("/api/projects/{project_id}/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def update_project_subscription(project_id: str, sub_id: str, request: SubscriptionUpdateRequest):
    """Update subscription label and/or description within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.get_subscription(sub_id)

    update_data = request.model_dump(exclude_unset=True)

    if "label" in update_data:
        sub.label = request.label if request.label else None
    if "description" in update_data:
        sub.description = request.description if request.description else None

    store.update_subscription(sub)
    return subscription_to_schema(sub)


@app.delete("/api/projects/{project_id}/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def delete_project_subscription(project_id: str, sub_id: str, hard: bool = Query(default=False)):
    """Delete (deactivate or hard delete) a subscription within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.remove_subscription(sub_id, hard=hard)
    return subscription_to_schema(sub)


@app.post("/api/projects/{project_id}/subscriptions/{sub_id}/reactivate", response_model=SubscriptionSchema)
def reactivate_project_subscription(project_id: str, sub_id: str):
    """Reactivate a deactivated subscription within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.get_subscription(sub_id)

    if sub.active:
        raise HTTPException(status_code=400, detail="Subscription is already active")

    sub.active = True
    store.update_subscription(sub)
    return subscription_to_schema(sub)


# --- Scan Endpoints ---


@app.post("/api/projects/{project_id}/scan", response_model=ScanHistoryEntrySchema)
def run_project_scan(project_id: str, request: ScanRequest):
    """
    Run a scan for a project and save to history.

    Special ref values:
    - "baseline": Use project's configured baseline ref
    - "HEAD~N": N commits back from HEAD
    """
    store, repo = get_project_store_and_repo(project_id)
    config = store.load()

    # Resolve refs
    base_ref = request.base_ref
    target_ref = request.target_ref

    # Handle special values
    if base_ref == "baseline":
        base_ref = config.repo.baseline_ref

    # Resolve to commit hashes (empty target_ref means working directory)
    base_ref = repo.resolve_ref(base_ref)
    if target_ref:
        target_ref = repo.resolve_ref(target_ref)
    else:
        target_ref = None  # Working directory

    # Run scan
    detector = Detector(repo)
    result = detector.scan(config.subscriptions, base_ref, target_ref)

    # Convert to dict and save to history
    result_dict = result_to_dict(result)
    history = get_scan_history()
    entry = history.save_scan(project_id, result_dict)

    return ScanHistoryEntrySchema(
        id=entry.id,
        project_id=entry.project_id,
        base_ref=entry.base_ref,
        target_ref=entry.target_ref,
        trigger_count=entry.trigger_count,
        proposal_count=entry.proposal_count,
        unchanged_count=entry.unchanged_count,
        created_at=entry.created_at,
    )


@app.get("/api/projects/{project_id}/scan-history", response_model=ScanHistoryListResponse)
def list_scan_history(
    project_id: str,
    limit: int = Query(default=50, ge=1, le=100)
):
    """List scan history for a project."""
    # Validate project exists
    project_store = get_project_store()
    _ = project_store.get_project(project_id)

    history = get_scan_history()
    entries = history.list_scans(project_id, limit=limit)

    return ScanHistoryListResponse(
        scans=[
            ScanHistoryEntrySchema(
                id=e.id,
                project_id=e.project_id,
                base_ref=e.base_ref,
                target_ref=e.target_ref,
                trigger_count=e.trigger_count,
                proposal_count=e.proposal_count,
                unchanged_count=e.unchanged_count,
                created_at=e.created_at,
            )
            for e in entries
        ],
        count=len(entries),
    )


@app.get("/api/projects/{project_id}/scan-history/{scan_id}")
def get_scan_result(project_id: str, scan_id: str):
    """Get a specific scan result with full details."""
    # Validate project exists
    project_store = get_project_store()
    _ = project_store.get_project(project_id)

    history = get_scan_history()
    entry = history.get_scan(project_id, scan_id)

    return entry.to_dict()


@app.delete("/api/projects/{project_id}/scan-history")
def clear_project_scan_history(project_id: str):
    """Clear all scan history for a project."""
    # Validate project exists
    project_store = get_project_store()
    _ = project_store.get_project(project_id)

    history = get_scan_history()
    count = history.clear_project_history(project_id)

    return {"deleted": count}


@app.delete("/api/scan-history")
def clear_all_scan_history():
    """Clear all scan history for all projects."""
    history = get_scan_history()
    count = history.clear_all_history()

    return {"deleted": count}


# --- Apply Updates Endpoint ---


@app.post("/api/projects/{project_id}/apply-updates", response_model=ApplyUpdatesResponse)
def apply_project_updates(project_id: str, request: ApplyUpdatesRequest):
    """
    Apply proposals from a scan result.

    Updates subscriptions and advances baseline to the scan's target_ref.
    """
    store, repo = get_project_store_and_repo(project_id)

    # Get the scan result
    history = get_scan_history()
    entry = history.get_scan(project_id, request.scan_id)
    scan_result = entry.scan_result

    # Filter proposals if specific IDs requested
    proposals = scan_result.get("proposals", [])
    if request.proposal_ids:
        proposals = [p for p in proposals if p["subscription_id"] in request.proposal_ids]

    # Build update document format
    update_data = {
        "target_ref": scan_result.get("target_ref", ""),
        "proposals": proposals,
    }

    # Apply updates
    updater = Updater(store, repo)
    applied, warnings = updater.apply(update_data)

    return ApplyUpdatesResponse(
        applied=applied,
        warnings=warnings,
        new_baseline=scan_result.get("target_ref") if applied else None,
    )
</file>

<file path="src/codesub/cli.py">
"""Command-line interface for codesub."""

import argparse
import json
import sys
from pathlib import Path

from . import __version__
from .config_store import ConfigStore
from .errors import CodesubError
from .git_repo import GitRepo
from .models import Anchor, Subscription
from .utils import extract_anchors, format_subscription, parse_location
from .project_store import ProjectStore
from .scan_history import ScanHistory


def get_store_and_repo() -> tuple[ConfigStore, GitRepo]:
    """Get ConfigStore and GitRepo for the current directory."""
    repo = GitRepo()
    store = ConfigStore(repo.root)
    return store, repo


def cmd_init(args: argparse.Namespace) -> int:
    """Initialize codesub in the current repository."""
    try:
        repo = GitRepo()
        store = ConfigStore(repo.root)

        # Resolve baseline ref
        baseline = args.baseline or "HEAD"
        baseline_hash = repo.resolve_ref(baseline)

        config = store.init(baseline_hash, force=args.force)

        print(f"Initialized codesub at {store.config_dir}")
        print(f"Baseline: {baseline_hash[:12]} ({baseline})")
        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_add(args: argparse.Namespace) -> int:
    """Add a new subscription."""
    try:
        store, repo = get_store_and_repo()
        config = store.load()

        # Parse location
        path, start_line, end_line = parse_location(args.location)

        # Validate file exists at baseline
        baseline = config.repo.baseline_ref
        lines = repo.show_file(baseline, path)

        # Validate line range
        if end_line > len(lines):
            print(
                f"Error: Line range {start_line}-{end_line} exceeds file length ({len(lines)} lines)",
                file=sys.stderr,
            )
            return 1

        # Extract anchors
        context_before, watched_lines, context_after = extract_anchors(
            lines, start_line, end_line, context=args.context
        )
        anchors = Anchor(
            context_before=context_before,
            lines=watched_lines,
            context_after=context_after,
        )

        # Create subscription
        sub = Subscription.create(
            path=path,
            start_line=start_line,
            end_line=end_line,
            label=args.label,
            description=args.desc,
            anchors=anchors,
        )

        store.add_subscription(sub)

        location = f"{path}:{start_line}" if start_line == end_line else f"{path}:{start_line}-{end_line}"
        print(f"Added subscription: {sub.id[:8]}")
        print(f"  Location: {location}")
        if args.label:
            print(f"  Label: {args.label}")
        print(f"  Watching {end_line - start_line + 1} line(s)")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_list(args: argparse.Namespace) -> int:
    """List all subscriptions."""
    try:
        store, _ = get_store_and_repo()
        config = store.load()

        subs = config.subscriptions
        if not args.all:
            subs = [s for s in subs if s.active]

        if not subs:
            print("No subscriptions found.")
            return 0

        if args.json:
            data = [s.to_dict() for s in subs]
            print(json.dumps(data, indent=2))
        else:
            print(f"Subscriptions ({len(subs)}):")
            print(f"Baseline: {config.repo.baseline_ref[:12]}")
            print()
            for sub in subs:
                print(format_subscription(sub, verbose=args.verbose))

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_remove(args: argparse.Namespace) -> int:
    """Remove a subscription."""
    try:
        store, _ = get_store_and_repo()

        sub = store.remove_subscription(args.subscription_id, hard=args.hard)

        action = "Removed" if args.hard else "Deactivated"
        print(f"{action} subscription: {sub.id[:8]}")
        if sub.label:
            print(f"  Label: {sub.label}")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_scan(args: argparse.Namespace) -> int:
    """Scan for changes and report triggered subscriptions."""
    try:
        store, repo = get_store_and_repo()
        config = store.load()

        # Import detector here to avoid circular imports during module load
        from .detector import Detector

        # Resolve refs
        base_ref = args.base or config.repo.baseline_ref
        target_ref = repo.resolve_ref(args.target or "HEAD")
        base_ref = repo.resolve_ref(base_ref)

        if base_ref == target_ref:
            print("Base and target refs are the same. No changes to scan.")
            return 0

        # Run detection
        detector = Detector(repo)
        result = detector.scan(config.subscriptions, base_ref, target_ref)

        # Output results
        if args.json:
            from .update_doc import result_to_dict
            data = result_to_dict(result)
            print(json.dumps(data, indent=2))
        else:
            print(f"Scan: {base_ref[:12]} -> {target_ref[:12]}")
            print()

            if result.triggers:
                print(f"TRIGGERED ({len(result.triggers)}):")
                for trigger in result.triggers:
                    sub = trigger.subscription
                    label = f" [{sub.label}]" if sub.label else ""
                    location = f"{trigger.path}:{trigger.start_line}-{trigger.end_line}"
                    reasons = ", ".join(trigger.reasons)
                    print(f"  {sub.id[:8]}{label}")
                    print(f"    Location: {location}")
                    print(f"    Reason: {reasons}")
                print()

            if result.proposals:
                print(f"PROPOSED UPDATES ({len(result.proposals)}):")
                for prop in result.proposals:
                    sub = prop.subscription
                    label = f" [{sub.label}]" if sub.label else ""
                    old_loc = f"{prop.old_path}:{prop.old_start}-{prop.old_end}"
                    new_loc = f"{prop.new_path}:{prop.new_start}-{prop.new_end}"
                    reasons = ", ".join(prop.reasons)
                    print(f"  {sub.id[:8]}{label}")
                    print(f"    {old_loc} -> {new_loc}")
                    print(f"    Reason: {reasons}")
                    if prop.shift:
                        print(f"    Shift: {prop.shift:+d}")
                print()

            if result.unchanged:
                print(f"UNCHANGED ({len(result.unchanged)}):")
                for sub in result.unchanged:
                    label = f" [{sub.label}]" if sub.label else ""
                    print(f"  {sub.id[:8]}{label}")
                print()

        # Write update documents if requested
        if args.write_updates:
            from .update_doc import write_update_doc
            write_update_doc(result, args.write_updates)
            print(f"Wrote update document: {args.write_updates}")

        if args.write_md:
            from .update_doc import write_markdown_doc
            write_markdown_doc(result, args.write_md)
            print(f"Wrote markdown summary: {args.write_md}")

        # Exit code
        if args.fail_on_trigger and result.triggers:
            return 2

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_apply_updates(args: argparse.Namespace) -> int:
    """Apply update proposals from an update document."""
    try:
        store, repo = get_store_and_repo()

        from .updater import Updater

        updater = Updater(store, repo)

        # Load update document
        with open(args.update_doc, "r", encoding="utf-8") as f:
            update_data = json.load(f)

        if args.dry_run:
            print("Dry run - no changes will be made")
            print()

        applied, warnings = updater.apply(update_data, dry_run=args.dry_run)

        if warnings:
            print("Warnings:")
            for warning in warnings:
                print(f"  {warning}")
            print()

        if applied:
            print(f"Applied {len(applied)} update(s):")
            for sub_id in applied:
                print(f"  {sub_id[:8]}")
        else:
            print("No updates applied.")

        if not args.dry_run and applied:
            target_ref = update_data.get("target_ref", "")
            print(f"\nBaseline updated to: {target_ref[:12]}")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1
    except FileNotFoundError:
        print(f"Error: Update document not found: {args.update_doc}", file=sys.stderr)
        return 1
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in update document: {e}", file=sys.stderr)
        return 1


def cmd_projects_list(args: argparse.Namespace) -> int:
    """List registered projects."""
    try:
        store = ProjectStore()
        projects = store.list_projects()

        if not projects:
            print("No projects registered.")
            print("Add a project with: codesub projects add <path>")
            return 0

        if args.json:
            data = [p.to_dict() for p in projects]
            print(json.dumps(data, indent=2))
        else:
            print(f"Projects ({len(projects)}):")
            print()
            for p in projects:
                print(f"  {p.id[:8]}  {p.name}")
                print(f"           {p.path}")
                print()

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_projects_add(args: argparse.Namespace) -> int:
    """Add a project."""
    try:
        store = ProjectStore()
        project = store.add_project(path=args.path, name=args.name)

        print(f"Added project: {project.id[:8]}")
        print(f"  Name: {project.name}")
        print(f"  Path: {project.path}")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_projects_remove(args: argparse.Namespace) -> int:
    """Remove a project."""
    try:
        store = ProjectStore()
        project = store.remove_project(args.project_id)

        print(f"Removed project: {project.id[:8]} ({project.name})")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_scan_history_clear(args: argparse.Namespace) -> int:
    """Clear scan history."""
    try:
        history = ScanHistory()

        if args.project:
            count = history.clear_project_history(args.project)
            print(f"Cleared {count} scan(s) for project {args.project[:8]}")
        else:
            count = history.clear_all_history()
            print(f"Cleared {count} scan(s) from all projects")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_serve(args: argparse.Namespace) -> int:
    """Start the API server."""
    try:
        import uvicorn

        # Verify we're in a git repo
        repo = GitRepo()
        store = ConfigStore(repo.root)

        if not store.exists():
            print("Warning: codesub not initialized. Run 'codesub init' first.", file=sys.stderr)
            print("Starting server anyway...", file=sys.stderr)

        print("Starting codesub API server...")
        print(f"Repository: {repo.root}")
        print(f"API docs: http://{args.host}:{args.port}/docs")
        print()

        # When reload is enabled, uvicorn requires the app as an import string
        app_target = "codesub.api:app" if args.reload else None
        if app_target is None:
            from .api import app
            app_target = app

        uvicorn.run(
            app_target,
            host=args.host,
            port=args.port,
            reload=args.reload,
            workers=1,  # Single worker to avoid concurrent write issues
        )
        return 0

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def create_parser() -> argparse.ArgumentParser:
    """Create the argument parser."""
    parser = argparse.ArgumentParser(
        prog="codesub",
        description="Subscribe to file line ranges and detect changes via git diff.",
    )
    parser.add_argument(
        "--version", action="version", version=f"%(prog)s {__version__}"
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # init
    init_parser = subparsers.add_parser("init", help="Initialize codesub in the repository")
    init_parser.add_argument(
        "--baseline", "-b", help="Baseline ref (default: HEAD)"
    )
    init_parser.add_argument(
        "--force", "-f", action="store_true", help="Overwrite existing config"
    )

    # add
    add_parser = subparsers.add_parser("add", help="Add a new subscription")
    add_parser.add_argument(
        "location", help="Location to subscribe to (path:line or path:start-end)"
    )
    add_parser.add_argument("--label", "-l", help="Label for the subscription")
    add_parser.add_argument("--desc", "-d", help="Description")
    add_parser.add_argument(
        "--context", "-c", type=int, default=2,
        help="Number of context lines for anchors (default: 2)"
    )

    # list
    list_parser = subparsers.add_parser("list", help="List subscriptions")
    list_parser.add_argument(
        "--json", action="store_true", help="Output as JSON"
    )
    list_parser.add_argument(
        "--verbose", "-v", action="store_true", help="Show detailed info including anchors"
    )
    list_parser.add_argument(
        "--all", "-a", action="store_true", help="Include inactive subscriptions"
    )

    # remove
    remove_parser = subparsers.add_parser("remove", help="Remove a subscription")
    remove_parser.add_argument("subscription_id", help="Subscription ID (or prefix)")
    remove_parser.add_argument(
        "--hard", action="store_true", help="Delete entirely (default: deactivate)"
    )

    # scan
    scan_parser = subparsers.add_parser(
        "scan", help="Scan for changes and report triggered subscriptions"
    )
    scan_parser.add_argument(
        "--base", "-b", help="Base ref (default: config baseline)"
    )
    scan_parser.add_argument(
        "--target", "-t", help="Target ref (default: HEAD)"
    )
    scan_parser.add_argument(
        "--write-updates", "-w", help="Write JSON update document to path"
    )
    scan_parser.add_argument(
        "--write-md", "-m", help="Write markdown summary to path"
    )
    scan_parser.add_argument(
        "--json", action="store_true", help="Output as JSON"
    )
    scan_parser.add_argument(
        "--fail-on-trigger", action="store_true",
        help="Exit with code 2 if any subscriptions are triggered"
    )

    # apply-updates
    apply_parser = subparsers.add_parser(
        "apply-updates", help="Apply update proposals from an update document"
    )
    apply_parser.add_argument("update_doc", help="Path to update document JSON")
    apply_parser.add_argument(
        "--dry-run", action="store_true", help="Show what would be done without applying"
    )

    # serve
    serve_parser = subparsers.add_parser("serve", help="Start the API server")
    serve_parser.add_argument(
        "--host", default="127.0.0.1", help="Host to bind to (default: 127.0.0.1)"
    )
    serve_parser.add_argument(
        "--port", "-p", type=int, default=8000, help="Port to bind to (default: 8000)"
    )
    serve_parser.add_argument(
        "--reload", action="store_true", help="Enable auto-reload for development"
    )

    # projects (subcommand group)
    projects_parser = subparsers.add_parser("projects", help="Manage registered projects")
    projects_subparsers = projects_parser.add_subparsers(dest="projects_command")

    # projects list
    projects_list_parser = projects_subparsers.add_parser("list", help="List registered projects")
    projects_list_parser.add_argument("--json", action="store_true", help="Output as JSON")

    # projects add
    projects_add_parser = projects_subparsers.add_parser("add", help="Add a project")
    projects_add_parser.add_argument("path", help="Path to git repository")
    projects_add_parser.add_argument("--name", "-n", help="Display name (defaults to dir name)")

    # projects remove
    projects_remove_parser = projects_subparsers.add_parser("remove", help="Remove a project")
    projects_remove_parser.add_argument("project_id", help="Project ID")

    # scan-history
    scan_history_parser = subparsers.add_parser("scan-history", help="Manage scan history")
    scan_history_subparsers = scan_history_parser.add_subparsers(dest="scan_history_command")

    # scan-history clear
    scan_history_clear_parser = scan_history_subparsers.add_parser("clear", help="Clear scan history")
    scan_history_clear_parser.add_argument(
        "--project", "-p", help="Clear only for specific project ID"
    )

    return parser


def main() -> int:
    """Main entry point."""
    parser = create_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 0

    # Handle projects subcommands
    if args.command == "projects":
        if not hasattr(args, "projects_command") or not args.projects_command:
            parser.parse_args(["projects", "--help"])
            return 0
        if args.projects_command == "list":
            return cmd_projects_list(args)
        elif args.projects_command == "add":
            return cmd_projects_add(args)
        elif args.projects_command == "remove":
            return cmd_projects_remove(args)

    # Handle scan-history subcommands
    if args.command == "scan-history":
        if not hasattr(args, "scan_history_command") or not args.scan_history_command:
            parser.parse_args(["scan-history", "--help"])
            return 0
        if args.scan_history_command == "clear":
            return cmd_scan_history_clear(args)

    commands = {
        "init": cmd_init,
        "add": cmd_add,
        "list": cmd_list,
        "remove": cmd_remove,
        "scan": cmd_scan,
        "apply-updates": cmd_apply_updates,
        "serve": cmd_serve,
    }

    cmd_func = commands.get(args.command)
    if cmd_func:
        return cmd_func(args)

    parser.print_help()
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="src/codesub/detector.py">
"""Change detection for codesub."""

from .diff_parser import DiffParser, ranges_overlap
from .git_repo import GitRepo
from .models import FileDiff, Hunk, Proposal, ScanResult, Subscription, Trigger


class Detector:
    """Detects changes affecting subscriptions."""

    def __init__(self, repo: GitRepo):
        self.repo = repo
        self.parser = DiffParser()

    def scan(
        self,
        subscriptions: list[Subscription],
        base_ref: str,
        target_ref: str | None = None,
    ) -> ScanResult:
        """
        Scan for changes between two refs, or between a ref and working directory.

        Args:
            subscriptions: List of subscriptions to check.
            base_ref: Base git ref.
            target_ref: Target git ref, or None/empty for working directory.

        Returns:
            ScanResult with triggers, proposals, and unchanged subscriptions.
        """
        # Only process active subscriptions
        active_subs = [s for s in subscriptions if s.active]

        # Use "WORKING" to represent working directory
        display_target = target_ref or "WORKING"

        if not active_subs:
            return ScanResult(
                base_ref=base_ref,
                target_ref=display_target,
                triggers=[],
                proposals=[],
                unchanged=[],
            )

        # Get diffs
        patch_text = self.repo.diff_patch(base_ref, target_ref)
        name_status_text = self.repo.diff_name_status(base_ref, target_ref)

        # Parse diffs
        file_diffs = self.parser.parse_patch(patch_text)
        rename_map, status_map = self.parser.parse_name_status(name_status_text)

        # Build lookup by old path
        diff_by_path: dict[str, FileDiff] = {}
        for fd in file_diffs:
            diff_by_path[fd.old_path] = fd

        triggers: list[Trigger] = []
        proposals: list[Proposal] = []
        unchanged: list[Subscription] = []

        for sub in active_subs:
            # Check if file was renamed
            new_path = rename_map.get(sub.path, sub.path)
            is_renamed = new_path != sub.path

            # Check if file was deleted
            file_status = status_map.get(sub.path, "")
            is_deleted = file_status == "D"

            # Get diff for this file
            file_diff = diff_by_path.get(sub.path)

            # Check for triggers
            trigger = self._check_trigger(sub, file_diff, is_deleted)

            if trigger:
                triggers.append(trigger)
            else:
                # Check for proposals (shift or rename)
                proposal = self._compute_proposal(
                    sub, file_diff, is_renamed, new_path
                )
                if proposal:
                    proposals.append(proposal)
                else:
                    unchanged.append(sub)

        return ScanResult(
            base_ref=base_ref,
            target_ref=display_target,
            triggers=triggers,
            proposals=proposals,
            unchanged=unchanged,
        )

    def _check_trigger(
        self,
        sub: Subscription,
        file_diff: FileDiff | None,
        is_deleted: bool,
    ) -> Trigger | None:
        """
        Check if a subscription is triggered by changes.

        Returns:
            Trigger if triggered, None otherwise.
        """
        if is_deleted:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=["file_deleted"],
                matching_hunks=[],
            )

        if file_diff is None:
            return None

        if file_diff.is_deleted_file:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=["file_deleted"],
                matching_hunks=[],
            )

        matching_hunks: list[Hunk] = []
        reasons: list[str] = []

        for hunk in file_diff.hunks:
            if hunk.old_count > 0:
                # Modification or deletion: check for overlap
                hunk_start = hunk.old_start
                hunk_end = hunk.old_start + hunk.old_count - 1

                if ranges_overlap(sub.start_line, sub.end_line, hunk_start, hunk_end):
                    matching_hunks.append(hunk)
                    if "overlap_hunk" not in reasons:
                        reasons.append("overlap_hunk")
            else:
                # Pure insertion (old_count == 0)
                # In git diff, old_start is the line AFTER which new content is inserted.
                #
                # Trigger semantics (conservative - trigger if insertion could affect
                # the logical unit being watched):
                # - Insert after line 5 when watching 5-10: triggers (between watched lines)
                # - Insert after line 4 when watching 5-10: doesn't trigger (before range, will shift)
                # - Insert after line 9 when watching 5-10: triggers (between watched lines)
                # - Insert after line 10 when watching 5-10: doesn't trigger (after range)
                #
                # Condition: sub_start <= old_start < sub_end
                # This triggers when insertion is between the first and last watched lines
                # but NOT when insertion is immediately after the last line.
                if sub.start_line <= hunk.old_start < sub.end_line:
                    matching_hunks.append(hunk)
                    if "insert_inside_range" not in reasons:
                        reasons.append("insert_inside_range")

        if reasons:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=reasons,
                matching_hunks=matching_hunks,
            )

        return None

    def _compute_proposal(
        self,
        sub: Subscription,
        file_diff: FileDiff | None,
        is_renamed: bool,
        new_path: str,
    ) -> Proposal | None:
        """
        Compute a proposal for updating a subscription (shift or rename).

        Only called for non-triggered subscriptions.

        Returns:
            Proposal if updates needed, None otherwise.
        """
        shift = 0

        if file_diff is not None and file_diff.hunks:
            shift = self._calculate_shift(sub, file_diff.hunks)

        # Create proposal if there's a shift or rename
        if shift != 0 or is_renamed:
            reasons = []
            if is_renamed:
                reasons.append("rename")
            if shift != 0:
                reasons.append("line_shift")

            return Proposal(
                subscription_id=sub.id,
                subscription=sub,
                old_path=sub.path,
                old_start=sub.start_line,
                old_end=sub.end_line,
                new_path=new_path,
                new_start=sub.start_line + shift,
                new_end=sub.end_line + shift,
                reasons=reasons,
                confidence="high",
                shift=shift if shift != 0 else None,
            )

        return None

    def _calculate_shift(self, sub: Subscription, hunks: list[Hunk]) -> int:
        """
        Calculate line number shift for a subscription.

        IMPORTANT: This should only be called for non-triggered subscriptions,
        meaning no hunk overlaps with the subscription range.

        Args:
            sub: The subscription.
            hunks: List of hunks from the file diff (will be sorted if needed).

        Returns:
            Net shift in line numbers.
        """
        # Defensive sort - ensure hunks are in ascending old_start order
        sorted_hunks = sorted(hunks, key=lambda h: h.old_start)

        shift = 0
        sub_start = sub.start_line

        for hunk in sorted_hunks:
            delta = hunk.new_count - hunk.old_count

            if hunk.old_count == 0:
                # Pure insertion: affects lines > old_start
                # old_start is the line AFTER which insertion happens
                if hunk.old_start < sub_start:
                    shift += delta
            else:
                # Modification/deletion: old_end = old_start + old_count - 1
                old_end = hunk.old_start + hunk.old_count - 1

                if old_end < sub_start:
                    # Hunk is entirely before subscription
                    shift += delta
                elif hunk.old_start > sub.end_line:
                    # Hunk is entirely after subscription, stop processing
                    # (hunks are sorted)
                    break
                # else: hunk overlaps subscription, but we shouldn't reach here
                # because overlapping hunks would have triggered the subscription

        return shift
</file>

<file path="src/codesub/errors.py">
"""Custom exceptions for codesub."""


class CodesubError(Exception):
    """Base exception for all codesub errors."""

    pass


class ConfigNotFoundError(CodesubError):
    """Raised when .codesub/subscriptions.json doesn't exist."""

    def __init__(self, path: str | None = None):
        self.path = path
        msg = "Config not initialized. Run 'codesub init' first."
        if path:
            msg = f"Config not found at {path}. Run 'codesub init' first."
        super().__init__(msg)


class ConfigExistsError(CodesubError):
    """Raised when trying to init but config already exists."""

    def __init__(self, path: str):
        self.path = path
        super().__init__(f"Config already exists at {path}. Use --force to overwrite.")


class InvalidSchemaVersionError(CodesubError):
    """Raised when config has an unsupported schema version."""

    def __init__(self, found: int, supported: int):
        self.found = found
        self.supported = supported
        super().__init__(
            f"Unsupported schema version {found}. This tool supports version {supported}."
        )


class SubscriptionNotFoundError(CodesubError):
    """Raised when a subscription ID doesn't exist."""

    def __init__(self, sub_id: str):
        self.sub_id = sub_id
        super().__init__(f"Subscription not found: {sub_id}")


class InvalidLocationError(CodesubError):
    """Raised when a location spec is invalid."""

    def __init__(self, location: str, reason: str | None = None):
        self.location = location
        msg = f"Invalid location: {location}"
        if reason:
            msg = f"{msg} ({reason})"
        super().__init__(msg)


class FileNotFoundAtRefError(CodesubError):
    """Raised when a file doesn't exist at the specified git ref."""

    def __init__(self, path: str, ref: str):
        self.path = path
        self.ref = ref
        super().__init__(f"File '{path}' not found at ref '{ref}'")


class GitError(CodesubError):
    """Raised when a git operation fails."""

    def __init__(self, command: str, stderr: str):
        self.command = command
        self.stderr = stderr
        super().__init__(f"Git command failed: {command}\n{stderr}")


class NotAGitRepoError(CodesubError):
    """Raised when not inside a git repository."""

    def __init__(self, path: str):
        self.path = path
        super().__init__(f"Not a git repository: {path}")


class InvalidLineRangeError(CodesubError):
    """Raised when line range is invalid."""

    def __init__(self, start: int, end: int, reason: str):
        self.start = start
        self.end = end
        super().__init__(f"Invalid line range {start}-{end}: {reason}")


class ProjectNotFoundError(CodesubError):
    """Raised when a project ID doesn't exist."""

    def __init__(self, project_id: str):
        self.project_id = project_id
        super().__init__(f"Project not found: {project_id}")


class InvalidProjectPathError(CodesubError):
    """Raised when a project path is invalid."""

    def __init__(self, path: str, reason: str):
        self.path = path
        self.reason = reason
        super().__init__(f"Invalid project path '{path}': {reason}")


class ScanNotFoundError(CodesubError):
    """Raised when a scan history entry doesn't exist."""

    def __init__(self, scan_id: str):
        self.scan_id = scan_id
        super().__init__(f"Scan not found: {scan_id}")
</file>

<file path="src/codesub/git_repo.py">
"""Git repository wrapper for codesub."""

import subprocess
from pathlib import Path

from .errors import FileNotFoundAtRefError, GitError, NotAGitRepoError
from .utils import normalize_path


class GitRepo:
    """Wrapper for git operations."""

    def __init__(self, start_dir: str | Path = "."):
        """
        Initialize GitRepo by finding the repository root.

        Args:
            start_dir: Directory to start searching from.

        Raises:
            NotAGitRepoError: If not inside a git repository.
        """
        self._start_dir = Path(start_dir).resolve()
        self._root: Path | None = None

    @property
    def root(self) -> Path:
        """Get the repository root directory (cached)."""
        if self._root is None:
            result = subprocess.run(
                ["git", "rev-parse", "--show-toplevel"],
                cwd=self._start_dir,
                capture_output=True,
                text=True,
            )
            if result.returncode != 0:
                raise NotAGitRepoError(str(self._start_dir))
            self._root = Path(result.stdout.strip())
        return self._root

    def head(self) -> str:
        """Get the current HEAD commit hash."""
        return self.resolve_ref("HEAD")

    def commit_title(self, ref: str, max_length: int = 50) -> str:
        """
        Get the commit title (subject line) for a ref.

        Args:
            ref: Git ref (commit hash, branch name, etc.).
            max_length: Maximum length before truncation (0 = no limit).

        Returns:
            Commit subject line, possibly truncated with "...".
        """
        result = subprocess.run(
            ["git", "log", "--format=%s", "-n", "1", ref],
            cwd=self.root,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            return ""
        title = result.stdout.strip()
        if max_length > 0 and len(title) > max_length:
            title = title[: max_length - 3] + "..."
        return title

    def resolve_ref(self, ref: str) -> str:
        """
        Resolve a git ref to a full commit hash.

        Args:
            ref: Git ref (e.g., "HEAD", "main", commit hash).

        Returns:
            Full commit hash.

        Raises:
            GitError: If ref cannot be resolved.
        """
        result = subprocess.run(
            ["git", "rev-parse", ref],
            cwd=self.root,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            raise GitError(f"git rev-parse {ref}", result.stderr.strip())
        return result.stdout.strip()

    def show_file(self, ref: str, path: str) -> list[str]:
        """
        Get file content at a specific ref.

        Args:
            ref: Git ref (commit hash, branch name, etc.).
            path: Repo-relative path to the file.

        Returns:
            List of lines (without trailing newlines).

        Raises:
            FileNotFoundAtRefError: If file doesn't exist at ref.
            GitError: If git command fails for other reasons.
        """
        path = normalize_path(path)
        result = subprocess.run(
            ["git", "show", f"{ref}:{path}"],
            cwd=self.root,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            stderr = result.stderr.strip()
            if "does not exist" in stderr or "exists on disk" in stderr:
                raise FileNotFoundAtRefError(path, ref)
            raise GitError(f"git show {ref}:{path}", stderr)

        # Split into lines, preserving empty lines but removing trailing newline
        content = result.stdout
        if content.endswith("\n"):
            content = content[:-1]
        if not content:
            return []
        return content.split("\n")

    def diff_patch(self, base: str, target: str | None = None) -> str:
        """
        Get unified diff between two refs, or between a ref and working directory.

        Uses -U0 for minimal context (just hunks).

        Args:
            base: Base ref.
            target: Target ref, or None/empty for working directory.

        Returns:
            Diff text (may be empty if no changes).
        """
        if target:
            cmd = ["git", "diff", "-U0", "--find-renames", base, target]
        else:
            # Compare base to working directory (uncommitted changes)
            cmd = ["git", "diff", "-U0", "--find-renames", base]
        result = subprocess.run(
            cmd,
            cwd=self.root,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            raise GitError(f"git diff {base} {target or '(working)'}", result.stderr.strip())
        return result.stdout

    def diff_name_status(self, base: str, target: str | None = None) -> str:
        """
        Get name-status diff between two refs, or between a ref and working directory.

        Args:
            base: Base ref.
            target: Target ref, or None/empty for working directory.

        Returns:
            Name-status output text.
        """
        if target:
            cmd = ["git", "diff", "--name-status", "-M", "--find-renames", base, target]
        else:
            cmd = ["git", "diff", "--name-status", "-M", "--find-renames", base]
        result = subprocess.run(
            cmd,
            cwd=self.root,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            raise GitError(f"git diff --name-status {base} {target or '(working)'}", result.stderr.strip())
        return result.stdout

    def file_line_count(self, ref: str, path: str) -> int:
        """Get the number of lines in a file at a ref."""
        lines = self.show_file(ref, path)
        return len(lines)

    def relative_path(self, abs_path: str | Path) -> str:
        """
        Convert an absolute path to a repo-relative path.

        Args:
            abs_path: Absolute or relative path.

        Returns:
            Repo-relative POSIX path.
        """
        path = Path(abs_path).resolve()
        try:
            rel = path.relative_to(self.root)
            return normalize_path(str(rel))
        except ValueError:
            # Path is not inside repo, return as-is normalized
            return normalize_path(str(path))
</file>

<file path="src/codesub/models.py">
"""Data models for codesub."""

from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any
import uuid


def _utc_now() -> str:
    """Return current UTC time as ISO 8601 string."""
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")


def _generate_id() -> str:
    """Generate a new subscription ID."""
    return str(uuid.uuid4())


@dataclass
class Anchor:
    """Context lines around a subscription for display and future fuzzy matching."""

    context_before: list[str]
    lines: list[str]
    context_after: list[str]

    def to_dict(self) -> dict[str, Any]:
        return {
            "context_before": self.context_before,
            "lines": self.lines,
            "context_after": self.context_after,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Anchor":
        return cls(
            context_before=data.get("context_before", []),
            lines=data.get("lines", []),
            context_after=data.get("context_after", []),
        )


@dataclass
class Subscription:
    """A subscription to a file line range."""

    id: str
    path: str  # repo-relative, POSIX-style
    start_line: int  # 1-based inclusive
    end_line: int  # 1-based inclusive
    label: str | None = None
    description: str | None = None
    anchors: Anchor | None = None
    active: bool = True
    created_at: str = field(default_factory=_utc_now)
    updated_at: str = field(default_factory=_utc_now)

    def to_dict(self) -> dict[str, Any]:
        result: dict[str, Any] = {
            "id": self.id,
            "path": self.path,
            "start_line": self.start_line,
            "end_line": self.end_line,
            "active": self.active,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
        }
        if self.label is not None:
            result["label"] = self.label
        if self.description is not None:
            result["description"] = self.description
        if self.anchors is not None:
            result["anchors"] = self.anchors.to_dict()
        return result

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Subscription":
        anchors = None
        if "anchors" in data:
            anchors = Anchor.from_dict(data["anchors"])
        return cls(
            id=data["id"],
            path=data["path"],
            start_line=data["start_line"],
            end_line=data["end_line"],
            label=data.get("label"),
            description=data.get("description"),
            anchors=anchors,
            active=data.get("active", True),
            created_at=data.get("created_at", ""),
            updated_at=data.get("updated_at", ""),
        )

    @classmethod
    def create(
        cls,
        path: str,
        start_line: int,
        end_line: int,
        label: str | None = None,
        description: str | None = None,
        anchors: Anchor | None = None,
    ) -> "Subscription":
        """Create a new subscription with generated ID and timestamps."""
        now = _utc_now()
        return cls(
            id=_generate_id(),
            path=path,
            start_line=start_line,
            end_line=end_line,
            label=label,
            description=description,
            anchors=anchors,
            active=True,
            created_at=now,
            updated_at=now,
        )


@dataclass
class RepoConfig:
    """Repository-level configuration."""

    baseline_ref: str
    created_at: str = field(default_factory=_utc_now)
    updated_at: str = field(default_factory=_utc_now)

    def to_dict(self) -> dict[str, Any]:
        return {
            "baseline_ref": self.baseline_ref,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "RepoConfig":
        return cls(
            baseline_ref=data["baseline_ref"],
            created_at=data.get("created_at", ""),
            updated_at=data.get("updated_at", ""),
        )


@dataclass
class Config:
    """Full configuration containing repo config and subscriptions."""

    schema_version: int
    repo: RepoConfig
    subscriptions: list[Subscription]

    def to_dict(self) -> dict[str, Any]:
        return {
            "schema_version": self.schema_version,
            "repo": self.repo.to_dict(),
            "subscriptions": [s.to_dict() for s in self.subscriptions],
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Config":
        return cls(
            schema_version=data["schema_version"],
            repo=RepoConfig.from_dict(data["repo"]),
            subscriptions=[Subscription.from_dict(s) for s in data.get("subscriptions", [])],
        )

    @classmethod
    def create(cls, baseline_ref: str) -> "Config":
        """Create a new config with the given baseline ref."""
        return cls(
            schema_version=1,
            repo=RepoConfig(baseline_ref=baseline_ref),
            subscriptions=[],
        )


# Models for diff parsing


@dataclass
class Hunk:
    """A single hunk from a unified diff."""

    old_start: int
    old_count: int
    new_start: int
    new_count: int


@dataclass
class FileDiff:
    """Diff information for a single file."""

    old_path: str
    new_path: str
    hunks: list[Hunk]
    is_rename: bool = False
    is_new_file: bool = False
    is_deleted_file: bool = False


# Models for detection results


@dataclass
class Trigger:
    """A subscription that was triggered by changes."""

    subscription_id: str
    subscription: Subscription
    path: str
    start_line: int
    end_line: int
    reasons: list[str]  # e.g., ["overlap_hunk", "file_deleted", "insert_inside_range"]
    matching_hunks: list[Hunk]


@dataclass
class Proposal:
    """A proposed update to a subscription (rename or line shift)."""

    subscription_id: str
    subscription: Subscription
    old_path: str
    old_start: int
    old_end: int
    new_path: str
    new_start: int
    new_end: int
    reasons: list[str]  # ["rename", "line_shift"]
    confidence: str = "high"  # "high" for POC (math-based)
    shift: int | None = None


@dataclass
class ScanResult:
    """Result of scanning for changes."""

    base_ref: str
    target_ref: str
    triggers: list[Trigger]
    proposals: list[Proposal]
    unchanged: list[Subscription]  # Subscriptions with no changes or shifts


# Models for multi-project management


@dataclass
class Project:
    """A registered project (git repository with codesub initialized)."""

    id: str
    name: str  # Display name (defaults to repo directory name)
    path: str  # Absolute path to the repository root
    created_at: str = field(default_factory=_utc_now)
    updated_at: str = field(default_factory=_utc_now)

    def to_dict(self) -> dict[str, Any]:
        return {
            "id": self.id,
            "name": self.name,
            "path": self.path,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Project":
        return cls(
            id=data["id"],
            name=data["name"],
            path=data["path"],
            created_at=data.get("created_at", ""),
            updated_at=data.get("updated_at", ""),
        )

    @classmethod
    def create(cls, name: str, path: str) -> "Project":
        """Create a new project with generated ID and timestamps."""
        now = _utc_now()
        return cls(
            id=_generate_id(),
            name=name,
            path=path,
            created_at=now,
            updated_at=now,
        )


@dataclass
class ScanHistoryEntry:
    """A persisted scan result."""

    id: str
    project_id: str
    base_ref: str
    target_ref: str
    trigger_count: int
    proposal_count: int
    unchanged_count: int
    created_at: str
    scan_result: dict[str, Any]  # Full ScanResult as dict

    def to_dict(self) -> dict[str, Any]:
        return {
            "id": self.id,
            "project_id": self.project_id,
            "base_ref": self.base_ref,
            "target_ref": self.target_ref,
            "trigger_count": self.trigger_count,
            "proposal_count": self.proposal_count,
            "unchanged_count": self.unchanged_count,
            "created_at": self.created_at,
            "scan_result": self.scan_result,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "ScanHistoryEntry":
        return cls(
            id=data["id"],
            project_id=data["project_id"],
            base_ref=data["base_ref"],
            target_ref=data["target_ref"],
            trigger_count=data["trigger_count"],
            proposal_count=data["proposal_count"],
            unchanged_count=data["unchanged_count"],
            created_at=data["created_at"],
            scan_result=data["scan_result"],
        )
</file>

</files>
