This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: src/codesub/semantic/python_indexer.py, src/codesub/semantic/fingerprint.py, src/codesub/semantic/__init__.py, src/codesub/detector.py, src/codesub/cli.py, src/codesub/api.py, src/codesub/models.py, src/codesub/utils.py, src/codesub/errors.py, tests/test_semantic.py, tests/test_semantic_detector.py, pyproject.toml
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
src/
  codesub/
    semantic/
      __init__.py
      fingerprint.py
      python_indexer.py
    api.py
    cli.py
    detector.py
    errors.py
    models.py
    utils.py
tests/
  test_semantic_detector.py
  test_semantic.py
pyproject.toml
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/codesub/semantic/__init__.py">
"""Semantic code analysis for codesub."""

from .fingerprint import compute_body_hash, compute_interface_hash
from .python_indexer import Construct, PythonIndexer

__all__ = [
    "Construct",
    "PythonIndexer",
    "compute_body_hash",
    "compute_interface_hash",
]
</file>

<file path="src/codesub/semantic/fingerprint.py">
"""Fingerprint computation for code constructs."""

from __future__ import annotations

import hashlib
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import tree_sitter


def compute_interface_hash(
    kind: str,
    annotation: str | None,
    decorators: list[str],
    params_node: "tree_sitter.Node | None" = None,
    source_bytes: bytes | None = None,
) -> str:
    """
    Compute interface hash (rename-resistant).

    Includes: kind, type annotation, decorators, method parameters with types/defaults
    Excludes: construct name
    """
    components = [kind]

    # Add type annotation
    components.append(annotation or "<no-annotation>")

    # Add sorted decorators
    components.extend(sorted(decorators))

    # Add method parameters if present
    if params_node and source_bytes:
        params_str = _normalize_params(params_node, source_bytes)
        components.append(params_str)

    return _hash(components)


def compute_body_hash(node: "tree_sitter.Node | None", source_bytes: bytes) -> str:
    """
    Compute body hash (content change detection).

    Includes: all tokens except comments and whitespace
    """
    if node is None:
        return _hash(["<no-default>"])

    tokens = _extract_tokens(node, source_bytes)
    return _hash(tokens)


def _normalize_params(params_node: "tree_sitter.Node", source_bytes: bytes) -> str:
    """Extract normalized parameter representation including types and defaults."""
    parts = []
    for child in params_node.children:
        if child.type in (
            "identifier",
            "typed_parameter",
            "default_parameter",
            "typed_default_parameter",
            "list_splat_pattern",
            "dictionary_splat_pattern",
        ):
            # Get full text including type annotations and defaults
            text = source_bytes[child.start_byte : child.end_byte].decode()
            # Normalize whitespace
            text = " ".join(text.split())
            parts.append(text)
    return ",".join(parts)


def _extract_tokens(node: "tree_sitter.Node", source_bytes: bytes) -> list[str]:
    """Extract leaf tokens, excluding comments and whitespace."""
    tokens: list[str] = []
    _collect_tokens(node, source_bytes, tokens)
    return tokens


def _collect_tokens(
    node: "tree_sitter.Node", source_bytes: bytes, tokens: list[str]
) -> None:
    """Recursively collect tokens."""
    # Skip comments
    if node.type == "comment":
        return

    # Leaf node - extract text
    if len(node.children) == 0:
        text = source_bytes[node.start_byte : node.end_byte].decode().strip()
        if text:  # Skip empty/whitespace-only
            tokens.append(text)
    else:
        for child in node.children:
            _collect_tokens(child, source_bytes, tokens)


def _hash(components: list[str]) -> str:
    """Hash components into 16-char hex digest."""
    content = "\x00".join(components)
    return hashlib.sha256(content.encode()).hexdigest()[:16]
</file>

<file path="src/codesub/semantic/python_indexer.py">
"""Python construct extraction using Tree-sitter."""

from __future__ import annotations

import re
from dataclasses import dataclass

import tree_sitter
import tree_sitter_python as tspython

from .fingerprint import compute_body_hash, compute_interface_hash


@dataclass(frozen=True)
class Construct:
    """A parsed code construct."""

    path: str
    kind: str  # "variable"|"field"|"method"
    qualname: str  # "MAX_RETRIES" | "User.role"
    role: str | None  # "const" for constants
    start_line: int
    end_line: int
    interface_hash: str
    body_hash: str
    has_parse_error: bool = False


class PythonIndexer:
    """Extracts constructs from Python source code."""

    def __init__(self) -> None:
        self._language = tree_sitter.Language(tspython.language())
        self._parser = tree_sitter.Parser(self._language)

    def index_file(self, source: str, path: str) -> list[Construct]:
        """Extract all constructs from source code."""
        tree = self._parser.parse(source.encode())
        has_errors = self._has_errors(tree.root_node)
        constructs: list[Construct] = []

        source_bytes = source.encode()

        # Extract module-level assignments (variables/constants)
        constructs.extend(
            self._extract_module_assignments(tree.root_node, source_bytes, path, has_errors)
        )

        # Extract classes with their fields and methods
        constructs.extend(
            self._extract_classes(tree.root_node, source_bytes, path, has_errors)
        )

        return constructs

    def find_construct(
        self, source: str, path: str, qualname: str, kind: str | None = None
    ) -> Construct | None:
        """Find a specific construct by qualname."""
        constructs = self.index_file(source, path)
        matches = [c for c in constructs if c.qualname == qualname]
        if kind:
            matches = [c for c in matches if c.kind == kind]
        return matches[0] if len(matches) == 1 else None

    def _has_errors(self, node: tree_sitter.Node) -> bool:
        """Check if tree contains ERROR nodes."""
        if node.type == "ERROR":
            return True
        return any(self._has_errors(child) for child in node.children)

    def _extract_module_assignments(
        self,
        root: tree_sitter.Node,
        source_bytes: bytes,
        path: str,
        has_errors: bool,
    ) -> list[Construct]:
        """Extract module-level variable/constant assignments."""
        constructs: list[Construct] = []

        for child in root.children:
            # Handle: NAME = value
            if child.type == "expression_statement":
                expr = child.children[0] if child.children else None
                if expr and expr.type == "assignment":
                    construct = self._parse_assignment(
                        expr, source_bytes, path, None, has_errors
                    )
                    if construct:
                        constructs.append(construct)

        return constructs

    def _extract_classes(
        self,
        root: tree_sitter.Node,
        source_bytes: bytes,
        path: str,
        has_errors: bool,
    ) -> list[Construct]:
        """Extract classes with their fields and methods."""
        constructs: list[Construct] = []

        for child in root.children:
            # Handle both plain class_definition and decorated classes
            class_node = None
            if child.type == "class_definition":
                class_node = child
            elif child.type == "decorated_definition":
                # Find the class_definition inside the decorated_definition
                for inner in child.children:
                    if inner.type == "class_definition":
                        class_node = inner
                        break

            if class_node is None:
                continue

            class_name = self._get_name(class_node)
            if not class_name:
                continue

            # Get class body
            body = class_node.child_by_field_name("body")
            if not body:
                continue

            for member in body.children:
                    # Class field: x = value
                    if member.type == "expression_statement":
                        expr = member.children[0] if member.children else None
                        if expr and expr.type == "assignment":
                            construct = self._parse_assignment(
                                expr, source_bytes, path, class_name, has_errors
                            )
                            if construct:
                                constructs.append(construct)

                    # Method: def name(...): ...
                    elif member.type == "function_definition":
                        construct = self._parse_method(
                            member, source_bytes, path, class_name, has_errors
                        )
                        if construct:
                            constructs.append(construct)

                    # Decorated method: @decorator def name(...): ...
                    elif member.type == "decorated_definition":
                        func = None
                        for c in member.children:
                            if c.type == "function_definition":
                                func = c
                                break
                        if func:
                            construct = self._parse_method(
                                func,
                                source_bytes,
                                path,
                                class_name,
                                has_errors,
                                decorated_node=member,
                            )
                            if construct:
                                constructs.append(construct)

        return constructs

    def _parse_assignment(
        self,
        node: tree_sitter.Node,
        source_bytes: bytes,
        path: str,
        class_name: str | None,
        has_errors: bool,
    ) -> Construct | None:
        """Parse: NAME = value  OR  NAME: type = value  OR  NAME: type"""
        # In tree-sitter-python 0.25+, type annotations are children of assignment nodes
        # Structure: assignment { identifier, ":", type, "=", value }
        # Or: assignment { identifier, ":", type } (annotation without value)
        # Or: assignment { identifier, "=", value } (plain assignment)

        # Find the identifier (first child that's an identifier)
        name_node = None
        type_node = None
        value_node = None

        for child in node.children:
            if child.type == "identifier" and name_node is None:
                name_node = child
            elif child.type == "type":
                type_node = child

        # Try field-based access for left/right (works for plain assignments)
        left = node.child_by_field_name("left")
        right = node.child_by_field_name("right")

        # Use field-based name if available, otherwise use first identifier
        if left and left.type == "identifier":
            name_node = left
        if right:
            value_node = right

        # For annotated assignments, the value might be the last non-punctuation child
        if value_node is None and type_node is not None:
            # Find value after the "=" sign
            found_equals = False
            for child in node.children:
                if child.type == "=":
                    found_equals = True
                elif found_equals and child.type not in (":", "=", "type"):
                    value_node = child
                    break

        if not name_node or name_node.type != "identifier":
            return None

        name = self._node_text(name_node, source_bytes)
        qualname = f"{class_name}.{name}" if class_name else name
        kind = "field" if class_name else "variable"
        role = "const" if self._is_constant_name(name) else None

        # interface_hash: includes type annotation if present
        annotation = None
        if type_node:
            annotation = self._node_text(type_node, source_bytes)
        interface_hash = compute_interface_hash(kind, annotation=annotation, decorators=[])

        # body_hash: the RHS value (or "<no-default>" if no value)
        if value_node:
            body_hash = compute_body_hash(value_node, source_bytes)
        else:
            body_hash = compute_body_hash(None, source_bytes)

        return Construct(
            path=path,
            kind=kind,
            qualname=qualname,
            role=role,
            start_line=node.start_point[0] + 1,
            end_line=node.end_point[0] + 1,
            interface_hash=interface_hash,
            body_hash=body_hash,
            has_parse_error=has_errors,
        )

    def _parse_method(
        self,
        node: tree_sitter.Node,
        source_bytes: bytes,
        path: str,
        class_name: str,
        has_errors: bool,
        decorated_node: tree_sitter.Node | None = None,
    ) -> Construct | None:
        """Parse method definition."""
        name = self._get_name(node)
        if not name:
            return None

        qualname = f"{class_name}.{name}"

        # Get decorators
        decorators: list[str] = []
        if decorated_node:
            for child in decorated_node.children:
                if child.type == "decorator":
                    decorators.append(self._node_text(child, source_bytes))

        # Get parameters for interface_hash
        params_node = node.child_by_field_name("parameters")
        return_type = node.child_by_field_name("return_type")

        interface_hash = compute_interface_hash(
            "method",
            annotation=self._node_text(return_type, source_bytes) if return_type else None,
            decorators=decorators,
            params_node=params_node,
            source_bytes=source_bytes,
        )

        # Get body for body_hash
        body_node = node.child_by_field_name("body")
        body_hash = compute_body_hash(body_node, source_bytes) if body_node else ""

        use_node = decorated_node or node
        return Construct(
            path=path,
            kind="method",
            qualname=qualname,
            role=None,
            start_line=use_node.start_point[0] + 1,
            end_line=use_node.end_point[0] + 1,
            interface_hash=interface_hash,
            body_hash=body_hash,
            has_parse_error=has_errors,
        )

    def _get_name(self, node: tree_sitter.Node) -> str | None:
        """Get name from class/function definition."""
        name_node = node.child_by_field_name("name")
        if name_node:
            return name_node.text.decode() if name_node.text else None
        return None

    def _node_text(self, node: tree_sitter.Node, source_bytes: bytes) -> str:
        """Get text content of a node."""
        return source_bytes[node.start_byte : node.end_byte].decode()

    def _is_constant_name(self, name: str) -> bool:
        """Check if name follows CONSTANT_CASE convention."""
        return bool(re.match(r"^[A-Z][A-Z0-9_]*$", name))
</file>

<file path="tests/test_semantic_detector.py">
"""Integration tests for semantic subscription detection."""

import os
import pytest
import tempfile
import subprocess
from pathlib import Path

from codesub.config_store import ConfigStore
from codesub.detector import Detector
from codesub.git_repo import GitRepo
from codesub.models import SemanticTarget, Subscription


def run_git(cwd, *args):
    """Run a git command in the given directory."""
    subprocess.run(["git", *args], cwd=cwd, check=True, capture_output=True)


def write_file(path, content):
    """Write content to a file."""
    path.write_text(content)


@pytest.fixture
def semantic_repo(tmp_path):
    """Create a git repo with Python files for semantic testing."""
    # Initialize git repo
    run_git(tmp_path, "init")
    run_git(tmp_path, "config", "user.email", "test@test.com")
    run_git(tmp_path, "config", "user.name", "Test")

    # Create initial Python file
    code_file = tmp_path / "config.py"
    write_file(
        code_file,
        '''"""Configuration module."""

MAX_RETRIES = 5
TIMEOUT: int = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return True
''',
    )

    run_git(tmp_path, "add", ".")
    run_git(tmp_path, "commit", "-m", "Initial commit")

    return tmp_path


class TestSemanticDetector:
    """Tests for semantic change detection."""

    def test_no_change_detected(self, semantic_repo):
        """Semantic subscription unchanged when no changes made."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        # Create subscription to MAX_RETRIES
        sub = Subscription.create(
            path="config.py",
            start_line=3,
            end_line=3,
            semantic=SemanticTarget(
                language="python",
                kind="variable",
                qualname="MAX_RETRIES",
                role="const",
                interface_hash="d1ffa42d3fae5078",  # Computed from the indexer
                body_hash="ef2d127de37b942b",
            ),
        )

        base_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, base_ref)

        assert len(result.triggers) == 0
        assert len(result.proposals) == 0
        assert len(result.unchanged) == 1

    def test_value_change_triggers_content(self, semantic_repo):
        """Changing value triggers CONTENT change."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        from codesub.semantic import PythonIndexer

        indexer = PythonIndexer()

        # Get initial fingerprints
        source = (semantic_repo / "config.py").read_text()
        construct = indexer.find_construct(source, "config.py", "MAX_RETRIES")

        # Create subscription
        sub = Subscription.create(
            path="config.py",
            start_line=construct.start_line,
            end_line=construct.end_line,
            semantic=SemanticTarget(
                language="python",
                kind=construct.kind,
                qualname=construct.qualname,
                role=construct.role,
                interface_hash=construct.interface_hash,
                body_hash=construct.body_hash,
            ),
        )

        base_ref = repo.resolve_ref("HEAD")

        # Modify the value
        write_file(
            semantic_repo / "config.py",
            '''"""Configuration module."""

MAX_RETRIES = 10
TIMEOUT: int = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return True
''',
        )
        run_git(semantic_repo, "add", ".")
        run_git(semantic_repo, "commit", "-m", "Change MAX_RETRIES")

        target_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, target_ref)

        assert len(result.triggers) == 1
        assert result.triggers[0].change_type == "CONTENT"
        assert "body_changed" in result.triggers[0].reasons

    def test_type_change_triggers_structural(self, semantic_repo):
        """Changing type annotation triggers STRUCTURAL change."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        from codesub.semantic import PythonIndexer

        indexer = PythonIndexer()

        # Get initial fingerprints for TIMEOUT (which has type annotation)
        source = (semantic_repo / "config.py").read_text()
        construct = indexer.find_construct(source, "config.py", "TIMEOUT")

        # Create subscription
        sub = Subscription.create(
            path="config.py",
            start_line=construct.start_line,
            end_line=construct.end_line,
            semantic=SemanticTarget(
                language="python",
                kind=construct.kind,
                qualname=construct.qualname,
                role=construct.role,
                interface_hash=construct.interface_hash,
                body_hash=construct.body_hash,
            ),
        )

        base_ref = repo.resolve_ref("HEAD")

        # Change the type annotation
        write_file(
            semantic_repo / "config.py",
            '''"""Configuration module."""

MAX_RETRIES = 5
TIMEOUT: float = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return True
''',
        )
        run_git(semantic_repo, "add", ".")
        run_git(semantic_repo, "commit", "-m", "Change TIMEOUT type")

        target_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, target_ref)

        assert len(result.triggers) == 1
        assert result.triggers[0].change_type == "STRUCTURAL"
        assert "interface_changed" in result.triggers[0].reasons

    def test_line_shift_creates_proposal(self, semantic_repo):
        """Moving construct creates proposal with new line numbers."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        from codesub.semantic import PythonIndexer

        indexer = PythonIndexer()

        # Get initial fingerprints
        source = (semantic_repo / "config.py").read_text()
        construct = indexer.find_construct(source, "config.py", "MAX_RETRIES")

        # Create subscription
        sub = Subscription.create(
            path="config.py",
            start_line=construct.start_line,
            end_line=construct.end_line,
            semantic=SemanticTarget(
                language="python",
                kind=construct.kind,
                qualname=construct.qualname,
                role=construct.role,
                interface_hash=construct.interface_hash,
                body_hash=construct.body_hash,
            ),
        )

        base_ref = repo.resolve_ref("HEAD")

        # Add lines before MAX_RETRIES
        write_file(
            semantic_repo / "config.py",
            '''"""Configuration module."""

# Added comment
# Another comment

MAX_RETRIES = 5
TIMEOUT: int = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return True
''',
        )
        run_git(semantic_repo, "add", ".")
        run_git(semantic_repo, "commit", "-m", "Add comments")

        target_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, target_ref)

        assert len(result.triggers) == 0  # No trigger (content unchanged)
        assert len(result.proposals) == 1
        assert result.proposals[0].reasons == ["line_shift"]
        assert result.proposals[0].new_start == 6  # Shifted down by 3 lines

    def test_rename_creates_proposal(self, semantic_repo):
        """Renaming construct creates proposal with new qualname."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        from codesub.semantic import PythonIndexer

        indexer = PythonIndexer()

        # Get initial fingerprints
        source = (semantic_repo / "config.py").read_text()
        construct = indexer.find_construct(source, "config.py", "MAX_RETRIES")

        # Create subscription
        sub = Subscription.create(
            path="config.py",
            start_line=construct.start_line,
            end_line=construct.end_line,
            semantic=SemanticTarget(
                language="python",
                kind=construct.kind,
                qualname=construct.qualname,
                role=construct.role,
                interface_hash=construct.interface_hash,
                body_hash=construct.body_hash,
            ),
        )

        base_ref = repo.resolve_ref("HEAD")

        # Rename the variable
        write_file(
            semantic_repo / "config.py",
            '''"""Configuration module."""

RETRY_COUNT = 5
TIMEOUT: int = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return True
''',
        )
        run_git(semantic_repo, "add", ".")
        run_git(semantic_repo, "commit", "-m", "Rename MAX_RETRIES")

        target_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, target_ref)

        # Should find via hash matching since content is the same
        assert len(result.proposals) == 1
        assert result.proposals[0].new_qualname == "RETRY_COUNT"
        assert "semantic_location" in result.proposals[0].reasons

    def test_deleted_construct_triggers_missing(self, semantic_repo):
        """Deleting construct triggers MISSING."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        from codesub.semantic import PythonIndexer

        indexer = PythonIndexer()

        # Get initial fingerprints
        source = (semantic_repo / "config.py").read_text()
        construct = indexer.find_construct(source, "config.py", "MAX_RETRIES")

        # Create subscription
        sub = Subscription.create(
            path="config.py",
            start_line=construct.start_line,
            end_line=construct.end_line,
            semantic=SemanticTarget(
                language="python",
                kind=construct.kind,
                qualname=construct.qualname,
                role=construct.role,
                interface_hash=construct.interface_hash,
                body_hash=construct.body_hash,
            ),
        )

        base_ref = repo.resolve_ref("HEAD")

        # Delete the variable
        write_file(
            semantic_repo / "config.py",
            '''"""Configuration module."""

TIMEOUT: int = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return True
''',
        )
        run_git(semantic_repo, "add", ".")
        run_git(semantic_repo, "commit", "-m", "Delete MAX_RETRIES")

        target_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, target_ref)

        assert len(result.triggers) == 1
        assert result.triggers[0].change_type == "MISSING"
        assert "semantic_target_missing" in result.triggers[0].reasons

    def test_cosmetic_change_no_trigger(self, semantic_repo):
        """Whitespace/formatting changes don't trigger."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        from codesub.semantic import PythonIndexer

        indexer = PythonIndexer()

        # Get initial fingerprints
        source = (semantic_repo / "config.py").read_text()
        construct = indexer.find_construct(source, "config.py", "MAX_RETRIES")

        # Create subscription
        sub = Subscription.create(
            path="config.py",
            start_line=construct.start_line,
            end_line=construct.end_line,
            semantic=SemanticTarget(
                language="python",
                kind=construct.kind,
                qualname=construct.qualname,
                role=construct.role,
                interface_hash=construct.interface_hash,
                body_hash=construct.body_hash,
            ),
        )

        base_ref = repo.resolve_ref("HEAD")

        # Add extra whitespace (cosmetic change)
        write_file(
            semantic_repo / "config.py",
            '''"""Configuration module."""

MAX_RETRIES  =  5
TIMEOUT: int = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return True
''',
        )
        run_git(semantic_repo, "add", ".")
        run_git(semantic_repo, "commit", "-m", "Cosmetic whitespace")

        target_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, target_ref)

        # No trigger because whitespace is normalized
        assert len(result.triggers) == 0
        assert len(result.unchanged) == 1

    def test_method_body_change(self, semantic_repo):
        """Changing method body triggers CONTENT."""
        repo = GitRepo(semantic_repo)
        detector = Detector(repo)

        from codesub.semantic import PythonIndexer

        indexer = PythonIndexer()

        # Get initial fingerprints
        source = (semantic_repo / "config.py").read_text()
        construct = indexer.find_construct(source, "config.py", "Config.validate")

        # Create subscription
        sub = Subscription.create(
            path="config.py",
            start_line=construct.start_line,
            end_line=construct.end_line,
            semantic=SemanticTarget(
                language="python",
                kind=construct.kind,
                qualname=construct.qualname,
                role=construct.role,
                interface_hash=construct.interface_hash,
                body_hash=construct.body_hash,
            ),
        )

        base_ref = repo.resolve_ref("HEAD")

        # Change method body
        write_file(
            semantic_repo / "config.py",
            '''"""Configuration module."""

MAX_RETRIES = 5
TIMEOUT: int = 30

class Config:
    debug: bool = False

    def validate(self) -> bool:
        return self.debug or True
''',
        )
        run_git(semantic_repo, "add", ".")
        run_git(semantic_repo, "commit", "-m", "Change validate body")

        target_ref = repo.resolve_ref("HEAD")
        result = detector.scan([sub], base_ref, target_ref)

        assert len(result.triggers) == 1
        assert result.triggers[0].change_type == "CONTENT"
        assert "body_changed" in result.triggers[0].reasons
</file>

<file path="tests/test_semantic.py">
"""Tests for semantic code analysis."""

import pytest

from codesub.semantic import Construct, PythonIndexer, compute_body_hash, compute_interface_hash
from codesub.utils import LineTarget, SemanticTargetSpec, parse_target_spec


class TestTargetParsing:
    """Tests for target specification parsing."""

    def test_line_target_single_line(self):
        result = parse_target_spec("path/to/file.py:42")
        assert isinstance(result, LineTarget)
        assert result.path == "path/to/file.py"
        assert result.start_line == 42
        assert result.end_line == 42

    def test_line_target_range(self):
        result = parse_target_spec("path/to/file.py:42-50")
        assert isinstance(result, LineTarget)
        assert result.path == "path/to/file.py"
        assert result.start_line == 42
        assert result.end_line == 50

    def test_semantic_target_simple(self):
        result = parse_target_spec("path/to/file.py::MAX_RETRIES")
        assert isinstance(result, SemanticTargetSpec)
        assert result.path == "path/to/file.py"
        assert result.qualname == "MAX_RETRIES"
        assert result.kind is None

    def test_semantic_target_qualified(self):
        result = parse_target_spec("path/to/file.py::User.role")
        assert isinstance(result, SemanticTargetSpec)
        assert result.path == "path/to/file.py"
        assert result.qualname == "User.role"
        assert result.kind is None

    def test_semantic_target_with_kind(self):
        result = parse_target_spec("path/to/file.py::field:User.role")
        assert isinstance(result, SemanticTargetSpec)
        assert result.path == "path/to/file.py"
        assert result.qualname == "User.role"
        assert result.kind == "field"

    def test_semantic_target_method_kind(self):
        result = parse_target_spec("path/to/file.py::method:User.save")
        assert isinstance(result, SemanticTargetSpec)
        assert result.path == "path/to/file.py"
        assert result.qualname == "User.save"
        assert result.kind == "method"


class TestPythonIndexer:
    """Tests for Python construct extraction."""

    def test_module_variable(self):
        indexer = PythonIndexer()
        source = "MAX_RETRIES = 5"
        constructs = indexer.index_file(source, "test.py")

        assert len(constructs) == 1
        c = constructs[0]
        assert c.kind == "variable"
        assert c.qualname == "MAX_RETRIES"
        assert c.role == "const"
        assert c.start_line == 1
        assert c.end_line == 1

    def test_module_variable_annotated(self):
        indexer = PythonIndexer()
        source = "timeout: int = 30"
        constructs = indexer.index_file(source, "test.py")

        assert len(constructs) == 1
        c = constructs[0]
        assert c.kind == "variable"
        assert c.qualname == "timeout"
        assert c.role is None  # lowercase is not a const

    def test_module_variable_annotation_only(self):
        indexer = PythonIndexer()
        source = "name: str"
        constructs = indexer.index_file(source, "test.py")

        assert len(constructs) == 1
        c = constructs[0]
        assert c.kind == "variable"
        assert c.qualname == "name"

    def test_class_field(self):
        indexer = PythonIndexer()
        source = """
class User:
    role: str = "user"
"""
        constructs = indexer.index_file(source, "test.py")

        assert len(constructs) == 1
        c = constructs[0]
        assert c.kind == "field"
        assert c.qualname == "User.role"
        assert c.role is None

    def test_class_field_unannotated(self):
        indexer = PythonIndexer()
        source = """
class Config:
    MAX_SIZE = 100
"""
        constructs = indexer.index_file(source, "test.py")

        assert len(constructs) == 1
        c = constructs[0]
        assert c.kind == "field"
        assert c.qualname == "Config.MAX_SIZE"
        assert c.role == "const"

    def test_class_method(self):
        indexer = PythonIndexer()
        source = """
class User:
    def save(self, path: str = "tmp") -> None:
        pass
"""
        constructs = indexer.index_file(source, "test.py")

        assert len(constructs) == 1
        c = constructs[0]
        assert c.kind == "method"
        assert c.qualname == "User.save"
        assert c.start_line == 3
        assert c.end_line == 4

    def test_decorated_method(self):
        indexer = PythonIndexer()
        source = """
class User:
    @property
    def name(self) -> str:
        return self._name
"""
        constructs = indexer.index_file(source, "test.py")

        assert len(constructs) == 1
        c = constructs[0]
        assert c.kind == "method"
        assert c.qualname == "User.name"
        assert c.start_line == 3  # Decorator line
        assert c.end_line == 5

    def test_find_construct(self):
        indexer = PythonIndexer()
        source = """
MAX_RETRIES = 5

class User:
    role: str = "user"

    def save(self) -> None:
        pass
"""
        construct = indexer.find_construct(source, "test.py", "User.role")
        assert construct is not None
        assert construct.kind == "field"
        assert construct.qualname == "User.role"

    def test_find_construct_with_kind(self):
        indexer = PythonIndexer()
        source = """
class User:
    role: str = "user"
"""
        construct = indexer.find_construct(
            source, "test.py", "User.role", kind="field"
        )
        assert construct is not None
        assert construct.kind == "field"

    def test_find_construct_not_found(self):
        indexer = PythonIndexer()
        source = "x = 1"
        construct = indexer.find_construct(source, "test.py", "y")
        assert construct is None

    def test_multiple_constructs(self):
        indexer = PythonIndexer()
        source = """
MAX_RETRIES = 5
TIMEOUT: int = 30

class User:
    role: str = "user"
    count = 0

    def save(self) -> None:
        pass

    @classmethod
    def create(cls) -> "User":
        return cls()
"""
        constructs = indexer.index_file(source, "test.py")

        names = [c.qualname for c in constructs]
        assert "MAX_RETRIES" in names
        assert "TIMEOUT" in names
        assert "User.role" in names
        assert "User.count" in names
        assert "User.save" in names
        assert "User.create" in names


class TestFingerprinting:
    """Tests for fingerprint computation."""

    def test_whitespace_ignored(self):
        indexer = PythonIndexer()
        source1 = "x = 5"
        source2 = "x  =  5"

        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        assert c1.interface_hash == c2.interface_hash
        assert c1.body_hash == c2.body_hash

    def test_value_change_detected(self):
        indexer = PythonIndexer()
        source1 = "x = 5"
        source2 = "x = 10"

        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        assert c1.interface_hash == c2.interface_hash  # Same interface
        assert c1.body_hash != c2.body_hash  # Different body

    def test_type_annotation_change_detected(self):
        indexer = PythonIndexer()
        source1 = "x: int = 5"
        source2 = "x: float = 5"

        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        assert c1.interface_hash != c2.interface_hash  # Different interface
        assert c1.body_hash == c2.body_hash  # Same body

    def test_annotation_added_detected(self):
        indexer = PythonIndexer()
        source1 = "x = 5"
        source2 = "x: int = 5"

        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        assert c1.interface_hash != c2.interface_hash  # Different interface

    def test_method_param_default_change(self):
        indexer = PythonIndexer()
        source1 = """
class C:
    def f(self, x=1):
        pass
"""
        source2 = """
class C:
    def f(self, x=2):
        pass
"""
        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        assert c1.interface_hash != c2.interface_hash  # Param defaults in interface

    def test_method_body_change(self):
        indexer = PythonIndexer()
        source1 = """
class C:
    def f(self):
        return 1
"""
        source2 = """
class C:
    def f(self):
        return 2
"""
        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        assert c1.interface_hash == c2.interface_hash  # Same interface
        assert c1.body_hash != c2.body_hash  # Different body

    def test_comment_ignored(self):
        indexer = PythonIndexer()
        source1 = """
class C:
    def f(self):
        return 1
"""
        source2 = """
class C:
    def f(self):
        # comment
        return 1
"""
        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        # Both hashes should be the same since comments are ignored
        assert c1.body_hash == c2.body_hash

    def test_decorator_affects_interface(self):
        indexer = PythonIndexer()
        source1 = """
class C:
    def f(self):
        pass
"""
        source2 = """
class C:
    @property
    def f(self):
        pass
"""
        c1 = indexer.index_file(source1, "test.py")[0]
        c2 = indexer.index_file(source2, "test.py")[0]

        assert c1.interface_hash != c2.interface_hash  # Decorator changes interface


class TestSemanticModels:
    """Tests for semantic data models."""

    def test_semantic_target_to_dict(self):
        from codesub.models import SemanticTarget

        target = SemanticTarget(
            language="python",
            kind="field",
            qualname="User.role",
            role=None,
            interface_hash="abc123",
            body_hash="def456",
        )

        data = target.to_dict()
        assert data["language"] == "python"
        assert data["kind"] == "field"
        assert data["qualname"] == "User.role"
        assert data["interface_hash"] == "abc123"
        assert data["body_hash"] == "def456"

    def test_semantic_target_from_dict(self):
        from codesub.models import SemanticTarget

        data = {
            "language": "python",
            "kind": "method",
            "qualname": "User.save",
            "role": None,
            "interface_hash": "abc",
            "body_hash": "def",
            "fingerprint_version": 1,
        }

        target = SemanticTarget.from_dict(data)
        assert target.language == "python"
        assert target.kind == "method"
        assert target.qualname == "User.save"

    def test_subscription_with_semantic(self):
        from codesub.models import SemanticTarget, Subscription

        semantic = SemanticTarget(
            language="python",
            kind="field",
            qualname="Config.TIMEOUT",
            role="const",
            interface_hash="abc",
            body_hash="def",
        )

        sub = Subscription.create(
            path="config.py",
            start_line=10,
            end_line=10,
            semantic=semantic,
        )

        assert sub.semantic is not None
        assert sub.semantic.qualname == "Config.TIMEOUT"

        # Round-trip through dict
        data = sub.to_dict()
        assert "semantic" in data

        restored = Subscription.from_dict(data)
        assert restored.semantic is not None
        assert restored.semantic.qualname == "Config.TIMEOUT"
</file>

<file path="src/codesub/errors.py">
"""Custom exceptions for codesub."""


class CodesubError(Exception):
    """Base exception for all codesub errors."""

    pass


class ConfigNotFoundError(CodesubError):
    """Raised when .codesub/subscriptions.json doesn't exist."""

    def __init__(self, path: str | None = None):
        self.path = path
        msg = "Config not initialized. Run 'codesub init' first."
        if path:
            msg = f"Config not found at {path}. Run 'codesub init' first."
        super().__init__(msg)


class ConfigExistsError(CodesubError):
    """Raised when trying to init but config already exists."""

    def __init__(self, path: str):
        self.path = path
        super().__init__(f"Config already exists at {path}. Use --force to overwrite.")


class InvalidSchemaVersionError(CodesubError):
    """Raised when config has an unsupported schema version."""

    def __init__(self, found: int, supported: int):
        self.found = found
        self.supported = supported
        super().__init__(
            f"Unsupported schema version {found}. This tool supports version {supported}."
        )


class SubscriptionNotFoundError(CodesubError):
    """Raised when a subscription ID doesn't exist."""

    def __init__(self, sub_id: str):
        self.sub_id = sub_id
        super().__init__(f"Subscription not found: {sub_id}")


class InvalidLocationError(CodesubError):
    """Raised when a location spec is invalid."""

    def __init__(self, location: str, reason: str | None = None):
        self.location = location
        msg = f"Invalid location: {location}"
        if reason:
            msg = f"{msg} ({reason})"
        super().__init__(msg)


class FileNotFoundAtRefError(CodesubError):
    """Raised when a file doesn't exist at the specified git ref."""

    def __init__(self, path: str, ref: str):
        self.path = path
        self.ref = ref
        super().__init__(f"File '{path}' not found at ref '{ref}'")


class GitError(CodesubError):
    """Raised when a git operation fails."""

    def __init__(self, command: str, stderr: str):
        self.command = command
        self.stderr = stderr
        super().__init__(f"Git command failed: {command}\n{stderr}")


class NotAGitRepoError(CodesubError):
    """Raised when not inside a git repository."""

    def __init__(self, path: str):
        self.path = path
        super().__init__(f"Not a git repository: {path}")


class InvalidLineRangeError(CodesubError):
    """Raised when line range is invalid."""

    def __init__(self, start: int, end: int, reason: str):
        self.start = start
        self.end = end
        super().__init__(f"Invalid line range {start}-{end}: {reason}")


class ProjectNotFoundError(CodesubError):
    """Raised when a project ID doesn't exist."""

    def __init__(self, project_id: str):
        self.project_id = project_id
        super().__init__(f"Project not found: {project_id}")


class InvalidProjectPathError(CodesubError):
    """Raised when a project path is invalid."""

    def __init__(self, path: str, reason: str):
        self.path = path
        self.reason = reason
        super().__init__(f"Invalid project path '{path}': {reason}")


class ScanNotFoundError(CodesubError):
    """Raised when a scan history entry doesn't exist."""

    def __init__(self, scan_id: str):
        self.scan_id = scan_id
        super().__init__(f"Scan not found: {scan_id}")
</file>

<file path="src/codesub/utils.py">
"""Utility functions for codesub."""

import re
from dataclasses import dataclass
from pathlib import Path

from .errors import InvalidLocationError, InvalidLineRangeError


@dataclass(frozen=True)
class LineTarget:
    """Line-based subscription target."""

    path: str
    start_line: int
    end_line: int


@dataclass(frozen=True)
class SemanticTargetSpec:
    """Semantic subscription target specification."""

    path: str
    qualname: str
    kind: str | None = None  # Optional kind for disambiguation


def parse_target_spec(spec: str) -> LineTarget | SemanticTargetSpec:
    """
    Parse target specification.

    Formats:
    - "path/to/file.py:42-50" -> LineTarget
    - "path/to/file.py::QualName" -> SemanticTargetSpec
    - "path/to/file.py::kind:QualName" -> SemanticTargetSpec with kind

    Raises:
        InvalidLocationError: If the location format is invalid.
    """
    if "::" in spec:
        path, rest = spec.split("::", 1)
        if not path or not rest:
            raise InvalidLocationError(spec, "expected 'path.py::QualName'")

        # Normalize path
        path = Path(path).as_posix()

        # Check for kind prefix: "field:User.role"
        # Valid kinds are: variable, field, method
        # Note: "const" is a role, not a kind - constants are kind="variable" with role="const"
        kind = None
        qualname = rest
        if ":" in rest and not rest.startswith(":"):
            maybe_kind, maybe_qualname = rest.split(":", 1)
            if maybe_kind in ("variable", "field", "method"):
                kind = maybe_kind
                qualname = maybe_qualname

        return SemanticTargetSpec(path=path, qualname=qualname, kind=kind)

    # Fall back to line-based parsing
    path, start, end = parse_location(spec)
    return LineTarget(path=path, start_line=start, end_line=end)


def parse_location(location: str) -> tuple[str, int, int]:
    """
    Parse a location spec into (path, start_line, end_line).

    Formats:
    - path/to/file:42 (single line)
    - path/to/file:42-45 (range)

    Returns:
        Tuple of (path, start_line, end_line), all 1-based inclusive.

    Raises:
        InvalidLocationError: If the location format is invalid.
        InvalidLineRangeError: If the line range is invalid.
    """
    # Match path:line or path:start-end
    match = re.match(r"^(.+):(\d+)(?:-(\d+))?$", location)
    if not match:
        raise InvalidLocationError(
            location, "expected format 'path:line' or 'path:start-end'"
        )

    path = match.group(1)
    start = int(match.group(2))
    end = int(match.group(3)) if match.group(3) else start

    if start < 1:
        raise InvalidLineRangeError(start, end, "start line must be >= 1")
    if end < start:
        raise InvalidLineRangeError(start, end, "end line must be >= start line")

    # Normalize path to POSIX style
    path = Path(path).as_posix()

    return path, start, end


def normalize_path(path: str) -> str:
    """Normalize a path to POSIX style (forward slashes)."""
    return Path(path).as_posix()


def extract_anchors(
    lines: list[str], start_line: int, end_line: int, context: int = 2
) -> tuple[list[str], list[str], list[str]]:
    """
    Extract anchor lines from file content.

    Args:
        lines: All lines of the file (0-indexed list).
        start_line: 1-based inclusive start line.
        end_line: 1-based inclusive end line.
        context: Number of context lines before/after.

    Returns:
        Tuple of (context_before, watched_lines, context_after).
    """
    # Convert to 0-based indices
    start_idx = start_line - 1
    end_idx = end_line  # exclusive for slicing

    # Extract watched lines
    watched = lines[start_idx:end_idx]

    # Extract context before
    ctx_before_start = max(0, start_idx - context)
    ctx_before = lines[ctx_before_start:start_idx]

    # Extract context after
    ctx_after_end = min(len(lines), end_idx + context)
    ctx_after = lines[end_idx:ctx_after_end]

    return ctx_before, watched, ctx_after


def format_subscription(sub: "Subscription", verbose: bool = False) -> str:
    """Format a subscription for display."""
    # Import here to avoid circular import
    from .models import Subscription

    status = "active" if sub.active else "inactive"
    label_str = f" [{sub.label}]" if sub.label else ""
    location = f"{sub.path}:{sub.start_line}"
    if sub.end_line != sub.start_line:
        location = f"{sub.path}:{sub.start_line}-{sub.end_line}"

    result = f"{sub.id[:8]}  {location}{label_str} ({status})"

    if verbose:
        if sub.description:
            result += f"\n         Description: {sub.description}"
        if sub.anchors:
            result += "\n         Lines:"
            for line in sub.anchors.lines:
                # Truncate long lines
                display_line = line[:60] + "..." if len(line) > 60 else line
                result += f"\n           | {display_line}"

    return result


def truncate_id(sub_id: str) -> str:
    """Truncate a subscription ID for display."""
    return sub_id[:8]
</file>

<file path="src/codesub/cli.py">
"""Command-line interface for codesub."""

import argparse
import json
import sys
from pathlib import Path

from . import __version__
from .config_store import ConfigStore
from .errors import CodesubError
from .git_repo import GitRepo
from .models import Anchor, SemanticTarget, Subscription
from .utils import (
    LineTarget,
    SemanticTargetSpec,
    extract_anchors,
    format_subscription,
    parse_target_spec,
)
from .project_store import ProjectStore
from .scan_history import ScanHistory


def get_store_and_repo() -> tuple[ConfigStore, GitRepo]:
    """Get ConfigStore and GitRepo for the current directory."""
    repo = GitRepo()
    store = ConfigStore(repo.root)
    return store, repo


def cmd_init(args: argparse.Namespace) -> int:
    """Initialize codesub in the current repository."""
    try:
        repo = GitRepo()
        store = ConfigStore(repo.root)

        # Resolve baseline ref
        baseline = args.baseline or "HEAD"
        baseline_hash = repo.resolve_ref(baseline)

        config = store.init(baseline_hash, force=args.force)

        print(f"Initialized codesub at {store.config_dir}")
        print(f"Baseline: {baseline_hash[:12]} ({baseline})")
        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_add(args: argparse.Namespace) -> int:
    """Add a new subscription."""
    try:
        store, repo = get_store_and_repo()
        config = store.load()
        baseline = config.repo.baseline_ref

        # Parse target specification
        target = parse_target_spec(args.location)

        if isinstance(target, SemanticTargetSpec):
            # Semantic subscription
            return _add_semantic_subscription(
                store, repo, baseline, target, args
            )
        else:
            # Line-based subscription
            return _add_line_subscription(
                store, repo, baseline, target, args
            )

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def _add_line_subscription(
    store: ConfigStore,
    repo: GitRepo,
    baseline: str,
    target: LineTarget,
    args: argparse.Namespace,
) -> int:
    """Add a line-based subscription."""
    lines = repo.show_file(baseline, target.path)

    # Validate line range
    if target.end_line > len(lines):
        print(
            f"Error: Line range {target.start_line}-{target.end_line} exceeds "
            f"file length ({len(lines)} lines)",
            file=sys.stderr,
        )
        return 1

    # Extract anchors
    context_before, watched_lines, context_after = extract_anchors(
        lines, target.start_line, target.end_line, context=args.context
    )
    anchors = Anchor(
        context_before=context_before,
        lines=watched_lines,
        context_after=context_after,
    )

    # Create subscription
    sub = Subscription.create(
        path=target.path,
        start_line=target.start_line,
        end_line=target.end_line,
        label=args.label,
        description=args.desc,
        anchors=anchors,
    )

    store.add_subscription(sub)

    location = (
        f"{target.path}:{target.start_line}"
        if target.start_line == target.end_line
        else f"{target.path}:{target.start_line}-{target.end_line}"
    )
    print(f"Added subscription: {sub.id[:8]}")
    print(f"  Location: {location}")
    if args.label:
        print(f"  Label: {args.label}")
    print(f"  Watching {target.end_line - target.start_line + 1} line(s)")

    return 0


def _add_semantic_subscription(
    store: ConfigStore,
    repo: GitRepo,
    baseline: str,
    target: SemanticTargetSpec,
    args: argparse.Namespace,
) -> int:
    """Add a semantic subscription."""
    from .semantic import PythonIndexer

    indexer = PythonIndexer()

    lines = repo.show_file(baseline, target.path)
    source = "\n".join(lines)

    construct = indexer.find_construct(
        source, target.path, target.qualname, target.kind
    )
    if construct is None:
        print(f"Error: Construct '{target.qualname}' not found in {target.path}")
        print("Use 'codesub symbols' to discover valid targets.")
        return 1

    # Extract anchors from construct lines
    context_before, watched_lines, context_after = extract_anchors(
        lines, construct.start_line, construct.end_line, context=args.context
    )
    anchors = Anchor(
        context_before=context_before,
        lines=watched_lines,
        context_after=context_after,
    )

    # Create semantic target
    semantic = SemanticTarget(
        language="python",
        kind=construct.kind,
        qualname=construct.qualname,
        role=construct.role,
        interface_hash=construct.interface_hash,
        body_hash=construct.body_hash,
    )

    sub = Subscription.create(
        path=target.path,
        start_line=construct.start_line,
        end_line=construct.end_line,
        label=args.label,
        description=args.desc,
        anchors=anchors,
        semantic=semantic,
    )

    store.add_subscription(sub)

    print(f"Added semantic subscription: {sub.id[:8]}")
    print(f"  Target: {construct.kind} {construct.qualname}")
    print(f"  Location: {target.path}:{construct.start_line}-{construct.end_line}")
    if args.label:
        print(f"  Label: {args.label}")

    return 0


def cmd_list(args: argparse.Namespace) -> int:
    """List all subscriptions."""
    try:
        store, _ = get_store_and_repo()
        config = store.load()

        subs = config.subscriptions
        if not args.all:
            subs = [s for s in subs if s.active]

        if not subs:
            print("No subscriptions found.")
            return 0

        if args.json:
            data = [s.to_dict() for s in subs]
            print(json.dumps(data, indent=2))
        else:
            print(f"Subscriptions ({len(subs)}):")
            print(f"Baseline: {config.repo.baseline_ref[:12]}")
            print()
            for sub in subs:
                print(format_subscription(sub, verbose=args.verbose))

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_remove(args: argparse.Namespace) -> int:
    """Remove a subscription."""
    try:
        store, _ = get_store_and_repo()

        sub = store.remove_subscription(args.subscription_id, hard=args.hard)

        action = "Removed" if args.hard else "Deactivated"
        print(f"{action} subscription: {sub.id[:8]}")
        if sub.label:
            print(f"  Label: {sub.label}")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_scan(args: argparse.Namespace) -> int:
    """Scan for changes and report triggered subscriptions."""
    try:
        store, repo = get_store_and_repo()
        config = store.load()

        # Import detector here to avoid circular imports during module load
        from .detector import Detector

        # Resolve refs
        base_ref = args.base or config.repo.baseline_ref
        target_ref = repo.resolve_ref(args.target or "HEAD")
        base_ref = repo.resolve_ref(base_ref)

        if base_ref == target_ref:
            print("Base and target refs are the same. No changes to scan.")
            return 0

        # Run detection
        detector = Detector(repo)
        result = detector.scan(config.subscriptions, base_ref, target_ref)

        # Output results
        if args.json:
            from .update_doc import result_to_dict
            data = result_to_dict(result)
            print(json.dumps(data, indent=2))
        else:
            print(f"Scan: {base_ref[:12]} -> {target_ref[:12]}")
            print()

            if result.triggers:
                print(f"TRIGGERED ({len(result.triggers)}):")
                for trigger in result.triggers:
                    sub = trigger.subscription
                    label = f" [{sub.label}]" if sub.label else ""
                    location = f"{trigger.path}:{trigger.start_line}-{trigger.end_line}"
                    reasons = ", ".join(trigger.reasons)
                    print(f"  {sub.id[:8]}{label}")
                    print(f"    Location: {location}")
                    print(f"    Reason: {reasons}")
                print()

            if result.proposals:
                print(f"PROPOSED UPDATES ({len(result.proposals)}):")
                for prop in result.proposals:
                    sub = prop.subscription
                    label = f" [{sub.label}]" if sub.label else ""
                    old_loc = f"{prop.old_path}:{prop.old_start}-{prop.old_end}"
                    new_loc = f"{prop.new_path}:{prop.new_start}-{prop.new_end}"
                    reasons = ", ".join(prop.reasons)
                    print(f"  {sub.id[:8]}{label}")
                    print(f"    {old_loc} -> {new_loc}")
                    print(f"    Reason: {reasons}")
                    if prop.shift:
                        print(f"    Shift: {prop.shift:+d}")
                print()

            if result.unchanged:
                print(f"UNCHANGED ({len(result.unchanged)}):")
                for sub in result.unchanged:
                    label = f" [{sub.label}]" if sub.label else ""
                    print(f"  {sub.id[:8]}{label}")
                print()

        # Write update documents if requested
        if args.write_updates:
            from .update_doc import write_update_doc
            write_update_doc(result, args.write_updates)
            print(f"Wrote update document: {args.write_updates}")

        if args.write_md:
            from .update_doc import write_markdown_doc
            write_markdown_doc(result, args.write_md)
            print(f"Wrote markdown summary: {args.write_md}")

        # Exit code
        if args.fail_on_trigger and result.triggers:
            return 2

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_apply_updates(args: argparse.Namespace) -> int:
    """Apply update proposals from an update document."""
    try:
        store, repo = get_store_and_repo()

        from .updater import Updater

        updater = Updater(store, repo)

        # Load update document
        with open(args.update_doc, "r", encoding="utf-8") as f:
            update_data = json.load(f)

        if args.dry_run:
            print("Dry run - no changes will be made")
            print()

        applied, warnings = updater.apply(update_data, dry_run=args.dry_run)

        if warnings:
            print("Warnings:")
            for warning in warnings:
                print(f"  {warning}")
            print()

        if applied:
            print(f"Applied {len(applied)} update(s):")
            for sub_id in applied:
                print(f"  {sub_id[:8]}")
        else:
            print("No updates applied.")

        if not args.dry_run and applied:
            target_ref = update_data.get("target_ref", "")
            print(f"\nBaseline updated to: {target_ref[:12]}")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1
    except FileNotFoundError:
        print(f"Error: Update document not found: {args.update_doc}", file=sys.stderr)
        return 1
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in update document: {e}", file=sys.stderr)
        return 1


def cmd_projects_list(args: argparse.Namespace) -> int:
    """List registered projects."""
    try:
        store = ProjectStore()
        projects = store.list_projects()

        if not projects:
            print("No projects registered.")
            print("Add a project with: codesub projects add <path>")
            return 0

        if args.json:
            data = [p.to_dict() for p in projects]
            print(json.dumps(data, indent=2))
        else:
            print(f"Projects ({len(projects)}):")
            print()
            for p in projects:
                print(f"  {p.id[:8]}  {p.name}")
                print(f"           {p.path}")
                print()

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_projects_add(args: argparse.Namespace) -> int:
    """Add a project."""
    try:
        store = ProjectStore()
        project = store.add_project(path=args.path, name=args.name)

        print(f"Added project: {project.id[:8]}")
        print(f"  Name: {project.name}")
        print(f"  Path: {project.path}")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_projects_remove(args: argparse.Namespace) -> int:
    """Remove a project."""
    try:
        store = ProjectStore()
        project = store.remove_project(args.project_id)

        print(f"Removed project: {project.id[:8]} ({project.name})")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_scan_history_clear(args: argparse.Namespace) -> int:
    """Clear scan history."""
    try:
        history = ScanHistory()

        if args.project:
            count = history.clear_project_history(args.project)
            print(f"Cleared {count} scan(s) for project {args.project[:8]}")
        else:
            count = history.clear_all_history()
            print(f"Cleared {count} scan(s) from all projects")

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_symbols(args: argparse.Namespace) -> int:
    """List discoverable code constructs in a file."""
    try:
        store, repo = get_store_and_repo()
        config = store.load()

        ref = args.ref or config.repo.baseline_ref
        lines = repo.show_file(ref, args.path)
        source = "\n".join(lines)

        from .semantic import PythonIndexer

        indexer = PythonIndexer()
        constructs = indexer.index_file(source, args.path)

        # Filter by kind if specified
        if args.kind:
            constructs = [c for c in constructs if c.kind == args.kind]

        # Filter by grep pattern if specified
        if args.grep:
            constructs = [c for c in constructs if args.grep in c.qualname]

        if args.json:
            data = [
                {
                    "path": c.path,
                    "kind": c.kind,
                    "qualname": c.qualname,
                    "start_line": c.start_line,
                    "end_line": c.end_line,
                    "role": c.role,
                }
                for c in constructs
            ]
            print(json.dumps(data, indent=2))
        else:
            if not constructs:
                print(f"No constructs found in {args.path}")
                return 0

            print(f"Constructs in {args.path} ({len(constructs)}):")
            print()
            for c in constructs:
                fqn = f"{c.path}::{c.qualname}"
                role_str = f" ({c.role})" if c.role else ""
                lines_str = (
                    f"{c.start_line}"
                    if c.start_line == c.end_line
                    else f"{c.start_line}-{c.end_line}"
                )
                print(f"  {c.kind:<10} {c.qualname}{role_str}")
                print(f"             Lines: {lines_str}")
                print(f"             FQN:   {fqn}")
                print()

        return 0

    except CodesubError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def cmd_serve(args: argparse.Namespace) -> int:
    """Start the API server."""
    try:
        import uvicorn

        # Verify we're in a git repo
        repo = GitRepo()
        store = ConfigStore(repo.root)

        if not store.exists():
            print("Warning: codesub not initialized. Run 'codesub init' first.", file=sys.stderr)
            print("Starting server anyway...", file=sys.stderr)

        print("Starting codesub API server...")
        print(f"Repository: {repo.root}")
        print(f"API docs: http://{args.host}:{args.port}/docs")
        print()

        # When reload is enabled, uvicorn requires the app as an import string
        app_target = "codesub.api:app" if args.reload else None
        if app_target is None:
            from .api import app
            app_target = app

        uvicorn.run(
            app_target,
            host=args.host,
            port=args.port,
            reload=args.reload,
            workers=1,  # Single worker to avoid concurrent write issues
        )
        return 0

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


def create_parser() -> argparse.ArgumentParser:
    """Create the argument parser."""
    parser = argparse.ArgumentParser(
        prog="codesub",
        description="Subscribe to file line ranges and detect changes via git diff.",
    )
    parser.add_argument(
        "--version", action="version", version=f"%(prog)s {__version__}"
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # init
    init_parser = subparsers.add_parser("init", help="Initialize codesub in the repository")
    init_parser.add_argument(
        "--baseline", "-b", help="Baseline ref (default: HEAD)"
    )
    init_parser.add_argument(
        "--force", "-f", action="store_true", help="Overwrite existing config"
    )

    # add
    add_parser = subparsers.add_parser("add", help="Add a new subscription")
    add_parser.add_argument(
        "location",
        help="Location to subscribe to. Line-based: 'path:line' or 'path:start-end'. "
        "Semantic: 'path::QualName' or 'path::kind:QualName'",
    )
    add_parser.add_argument("--label", "-l", help="Label for the subscription")
    add_parser.add_argument("--desc", "-d", help="Description")
    add_parser.add_argument(
        "--context", "-c", type=int, default=2,
        help="Number of context lines for anchors (default: 2)"
    )

    # list
    list_parser = subparsers.add_parser("list", help="List subscriptions")
    list_parser.add_argument(
        "--json", action="store_true", help="Output as JSON"
    )
    list_parser.add_argument(
        "--verbose", "-v", action="store_true", help="Show detailed info including anchors"
    )
    list_parser.add_argument(
        "--all", "-a", action="store_true", help="Include inactive subscriptions"
    )

    # remove
    remove_parser = subparsers.add_parser("remove", help="Remove a subscription")
    remove_parser.add_argument("subscription_id", help="Subscription ID (or prefix)")
    remove_parser.add_argument(
        "--hard", action="store_true", help="Delete entirely (default: deactivate)"
    )

    # symbols
    symbols_parser = subparsers.add_parser(
        "symbols", help="List discoverable code constructs in a file"
    )
    symbols_parser.add_argument("path", help="File path to analyze")
    symbols_parser.add_argument("--ref", help="Git ref (default: baseline)")
    symbols_parser.add_argument(
        "--kind",
        choices=["variable", "field", "method"],
        help="Filter by construct kind",
    )
    symbols_parser.add_argument("--grep", help="Filter by name pattern")
    symbols_parser.add_argument("--json", action="store_true", help="Output as JSON")

    # scan
    scan_parser = subparsers.add_parser(
        "scan", help="Scan for changes and report triggered subscriptions"
    )
    scan_parser.add_argument(
        "--base", "-b", help="Base ref (default: config baseline)"
    )
    scan_parser.add_argument(
        "--target", "-t", help="Target ref (default: HEAD)"
    )
    scan_parser.add_argument(
        "--write-updates", "-w", help="Write JSON update document to path"
    )
    scan_parser.add_argument(
        "--write-md", "-m", help="Write markdown summary to path"
    )
    scan_parser.add_argument(
        "--json", action="store_true", help="Output as JSON"
    )
    scan_parser.add_argument(
        "--fail-on-trigger", action="store_true",
        help="Exit with code 2 if any subscriptions are triggered"
    )

    # apply-updates
    apply_parser = subparsers.add_parser(
        "apply-updates", help="Apply update proposals from an update document"
    )
    apply_parser.add_argument("update_doc", help="Path to update document JSON")
    apply_parser.add_argument(
        "--dry-run", action="store_true", help="Show what would be done without applying"
    )

    # serve
    serve_parser = subparsers.add_parser("serve", help="Start the API server")
    serve_parser.add_argument(
        "--host", default="127.0.0.1", help="Host to bind to (default: 127.0.0.1)"
    )
    serve_parser.add_argument(
        "--port", "-p", type=int, default=8000, help="Port to bind to (default: 8000)"
    )
    serve_parser.add_argument(
        "--reload", action="store_true", help="Enable auto-reload for development"
    )

    # projects (subcommand group)
    projects_parser = subparsers.add_parser("projects", help="Manage registered projects")
    projects_subparsers = projects_parser.add_subparsers(dest="projects_command")

    # projects list
    projects_list_parser = projects_subparsers.add_parser("list", help="List registered projects")
    projects_list_parser.add_argument("--json", action="store_true", help="Output as JSON")

    # projects add
    projects_add_parser = projects_subparsers.add_parser("add", help="Add a project")
    projects_add_parser.add_argument("path", help="Path to git repository")
    projects_add_parser.add_argument("--name", "-n", help="Display name (defaults to dir name)")

    # projects remove
    projects_remove_parser = projects_subparsers.add_parser("remove", help="Remove a project")
    projects_remove_parser.add_argument("project_id", help="Project ID")

    # scan-history
    scan_history_parser = subparsers.add_parser("scan-history", help="Manage scan history")
    scan_history_subparsers = scan_history_parser.add_subparsers(dest="scan_history_command")

    # scan-history clear
    scan_history_clear_parser = scan_history_subparsers.add_parser("clear", help="Clear scan history")
    scan_history_clear_parser.add_argument(
        "--project", "-p", help="Clear only for specific project ID"
    )

    return parser


def main() -> int:
    """Main entry point."""
    parser = create_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 0

    # Handle projects subcommands
    if args.command == "projects":
        if not hasattr(args, "projects_command") or not args.projects_command:
            parser.parse_args(["projects", "--help"])
            return 0
        if args.projects_command == "list":
            return cmd_projects_list(args)
        elif args.projects_command == "add":
            return cmd_projects_add(args)
        elif args.projects_command == "remove":
            return cmd_projects_remove(args)

    # Handle scan-history subcommands
    if args.command == "scan-history":
        if not hasattr(args, "scan_history_command") or not args.scan_history_command:
            parser.parse_args(["scan-history", "--help"])
            return 0
        if args.scan_history_command == "clear":
            return cmd_scan_history_clear(args)

    commands = {
        "init": cmd_init,
        "add": cmd_add,
        "list": cmd_list,
        "remove": cmd_remove,
        "symbols": cmd_symbols,
        "scan": cmd_scan,
        "apply-updates": cmd_apply_updates,
        "serve": cmd_serve,
    }

    cmd_func = commands.get(args.command)
    if cmd_func:
        return cmd_func(args)

    parser.print_help()
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="src/codesub/detector.py">
"""Change detection for codesub."""

from typing import TYPE_CHECKING

from .diff_parser import DiffParser, ranges_overlap
from .git_repo import GitRepo
from .models import FileDiff, Hunk, Proposal, ScanResult, SemanticTarget, Subscription, Trigger

if TYPE_CHECKING:
    from .semantic import Construct


class Detector:
    """Detects changes affecting subscriptions."""

    def __init__(self, repo: GitRepo):
        self.repo = repo
        self.parser = DiffParser()

    def scan(
        self,
        subscriptions: list[Subscription],
        base_ref: str,
        target_ref: str | None = None,
    ) -> ScanResult:
        """
        Scan for changes between two refs, or between a ref and working directory.

        Args:
            subscriptions: List of subscriptions to check.
            base_ref: Base git ref.
            target_ref: Target git ref, or None/empty for working directory.

        Returns:
            ScanResult with triggers, proposals, and unchanged subscriptions.
        """
        # Only process active subscriptions
        active_subs = [s for s in subscriptions if s.active]

        # Use "WORKING" to represent working directory
        display_target = target_ref or "WORKING"

        if not active_subs:
            return ScanResult(
                base_ref=base_ref,
                target_ref=display_target,
                triggers=[],
                proposals=[],
                unchanged=[],
            )

        # Get diffs
        patch_text = self.repo.diff_patch(base_ref, target_ref)
        name_status_text = self.repo.diff_name_status(base_ref, target_ref)

        # Parse diffs
        file_diffs = self.parser.parse_patch(patch_text)
        rename_map, status_map = self.parser.parse_name_status(name_status_text)

        # Build lookup by old path
        diff_by_path: dict[str, FileDiff] = {}
        for fd in file_diffs:
            diff_by_path[fd.old_path] = fd

        triggers: list[Trigger] = []
        proposals: list[Proposal] = []
        unchanged: list[Subscription] = []

        for sub in active_subs:
            # Check if semantic subscription
            if sub.semantic is not None:
                trigger, proposal = self._check_semantic(
                    sub, base_ref, target_ref, rename_map, status_map
                )
                if trigger:
                    triggers.append(trigger)
                if proposal:
                    proposals.append(proposal)
                if not trigger and not proposal:
                    unchanged.append(sub)
                continue

            # Line-based subscription
            # Check if file was renamed
            new_path = rename_map.get(sub.path, sub.path)
            is_renamed = new_path != sub.path

            # Check if file was deleted
            file_status = status_map.get(sub.path, "")
            is_deleted = file_status == "D"

            # Get diff for this file
            file_diff = diff_by_path.get(sub.path)

            # Check for triggers
            trigger = self._check_trigger(sub, file_diff, is_deleted)

            if trigger:
                triggers.append(trigger)
            else:
                # Check for proposals (shift or rename)
                proposal = self._compute_proposal(
                    sub, file_diff, is_renamed, new_path
                )
                if proposal:
                    proposals.append(proposal)
                else:
                    unchanged.append(sub)

        return ScanResult(
            base_ref=base_ref,
            target_ref=display_target,
            triggers=triggers,
            proposals=proposals,
            unchanged=unchanged,
        )

    def _check_trigger(
        self,
        sub: Subscription,
        file_diff: FileDiff | None,
        is_deleted: bool,
    ) -> Trigger | None:
        """
        Check if a subscription is triggered by changes.

        Returns:
            Trigger if triggered, None otherwise.
        """
        if is_deleted:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=["file_deleted"],
                matching_hunks=[],
            )

        if file_diff is None:
            return None

        if file_diff.is_deleted_file:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=["file_deleted"],
                matching_hunks=[],
            )

        matching_hunks: list[Hunk] = []
        reasons: list[str] = []

        for hunk in file_diff.hunks:
            if hunk.old_count > 0:
                # Modification or deletion: check for overlap
                hunk_start = hunk.old_start
                hunk_end = hunk.old_start + hunk.old_count - 1

                if ranges_overlap(sub.start_line, sub.end_line, hunk_start, hunk_end):
                    matching_hunks.append(hunk)
                    if "overlap_hunk" not in reasons:
                        reasons.append("overlap_hunk")
            else:
                # Pure insertion (old_count == 0)
                # In git diff, old_start is the line AFTER which new content is inserted.
                #
                # Trigger semantics (conservative - trigger if insertion could affect
                # the logical unit being watched):
                # - Insert after line 5 when watching 5-10: triggers (between watched lines)
                # - Insert after line 4 when watching 5-10: doesn't trigger (before range, will shift)
                # - Insert after line 9 when watching 5-10: triggers (between watched lines)
                # - Insert after line 10 when watching 5-10: doesn't trigger (after range)
                #
                # Condition: sub_start <= old_start < sub_end
                # This triggers when insertion is between the first and last watched lines
                # but NOT when insertion is immediately after the last line.
                if sub.start_line <= hunk.old_start < sub.end_line:
                    matching_hunks.append(hunk)
                    if "insert_inside_range" not in reasons:
                        reasons.append("insert_inside_range")

        if reasons:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=reasons,
                matching_hunks=matching_hunks,
            )

        return None

    def _compute_proposal(
        self,
        sub: Subscription,
        file_diff: FileDiff | None,
        is_renamed: bool,
        new_path: str,
    ) -> Proposal | None:
        """
        Compute a proposal for updating a subscription (shift or rename).

        Only called for non-triggered subscriptions.

        Returns:
            Proposal if updates needed, None otherwise.
        """
        shift = 0

        if file_diff is not None and file_diff.hunks:
            shift = self._calculate_shift(sub, file_diff.hunks)

        # Create proposal if there's a shift or rename
        if shift != 0 or is_renamed:
            reasons = []
            if is_renamed:
                reasons.append("rename")
            if shift != 0:
                reasons.append("line_shift")

            return Proposal(
                subscription_id=sub.id,
                subscription=sub,
                old_path=sub.path,
                old_start=sub.start_line,
                old_end=sub.end_line,
                new_path=new_path,
                new_start=sub.start_line + shift,
                new_end=sub.end_line + shift,
                reasons=reasons,
                confidence="high",
                shift=shift if shift != 0 else None,
            )

        return None

    def _calculate_shift(self, sub: Subscription, hunks: list[Hunk]) -> int:
        """
        Calculate line number shift for a subscription.

        IMPORTANT: This should only be called for non-triggered subscriptions,
        meaning no hunk overlaps with the subscription range.

        Args:
            sub: The subscription.
            hunks: List of hunks from the file diff (will be sorted if needed).

        Returns:
            Net shift in line numbers.
        """
        # Defensive sort - ensure hunks are in ascending old_start order
        sorted_hunks = sorted(hunks, key=lambda h: h.old_start)

        shift = 0
        sub_start = sub.start_line

        for hunk in sorted_hunks:
            delta = hunk.new_count - hunk.old_count

            if hunk.old_count == 0:
                # Pure insertion: affects lines > old_start
                # old_start is the line AFTER which insertion happens
                if hunk.old_start < sub_start:
                    shift += delta
            else:
                # Modification/deletion: old_end = old_start + old_count - 1
                old_end = hunk.old_start + hunk.old_count - 1

                if old_end < sub_start:
                    # Hunk is entirely before subscription
                    shift += delta
                elif hunk.old_start > sub.end_line:
                    # Hunk is entirely after subscription, stop processing
                    # (hunks are sorted)
                    break
                # else: hunk overlaps subscription, but we shouldn't reach here
                # because overlapping hunks would have triggered the subscription

        return shift

    def _check_semantic(
        self,
        sub: Subscription,
        base_ref: str,
        target_ref: str | None,
        rename_map: dict[str, str],
        status_map: dict[str, str],
    ) -> tuple[Trigger | None, Proposal | None]:
        """Check semantic subscription for changes."""
        from .semantic import PythonIndexer

        indexer = PythonIndexer()

        # Resolve file rename
        old_path = sub.path
        new_path = rename_map.get(old_path, old_path)

        # Check if file deleted
        if status_map.get(old_path) == "D":
            return (
                Trigger(
                    subscription_id=sub.id,
                    subscription=sub,
                    path=old_path,
                    start_line=sub.start_line,
                    end_line=sub.end_line,
                    reasons=["file_deleted"],
                    matching_hunks=[],
                    change_type="MISSING",
                ),
                None,
            )

        # Get old file content
        old_source = "\n".join(self.repo.show_file(base_ref, old_path))

        # Get new file content
        try:
            if target_ref:
                new_source = "\n".join(self.repo.show_file(target_ref, new_path))
            else:
                # Working directory
                with open(self.repo.root / new_path) as f:
                    new_source = f.read()
        except Exception:
            return (
                Trigger(
                    subscription_id=sub.id,
                    subscription=sub,
                    path=old_path,
                    start_line=sub.start_line,
                    end_line=sub.end_line,
                    reasons=["file_not_found"],
                    matching_hunks=[],
                    change_type="MISSING",
                ),
                None,
            )

        assert sub.semantic is not None  # Type narrowing

        # Stage 1: Exact match by qualname
        old_construct = indexer.find_construct(
            old_source, old_path, sub.semantic.qualname, sub.semantic.kind
        )
        new_construct = indexer.find_construct(
            new_source, new_path, sub.semantic.qualname, sub.semantic.kind
        )

        if new_construct:
            # Found by exact qualname - check for changes
            trigger = self._classify_semantic_change(sub, old_construct, new_construct)
            proposal = None

            # Check if path changed (file renamed)
            if old_path != new_path:
                proposal = Proposal(
                    subscription_id=sub.id,
                    subscription=sub,
                    old_path=old_path,
                    old_start=sub.start_line,
                    old_end=sub.end_line,
                    new_path=new_path,
                    new_start=new_construct.start_line,
                    new_end=new_construct.end_line,
                    reasons=["rename"],
                    confidence="high",
                )
            elif (
                new_construct.start_line != sub.start_line
                or new_construct.end_line != sub.end_line
            ):
                proposal = Proposal(
                    subscription_id=sub.id,
                    subscription=sub,
                    old_path=old_path,
                    old_start=sub.start_line,
                    old_end=sub.end_line,
                    new_path=new_path,
                    new_start=new_construct.start_line,
                    new_end=new_construct.end_line,
                    reasons=["line_shift"],
                    confidence="high",
                )

            return trigger, proposal

        # Stage 2: Hash-based search
        new_constructs = indexer.index_file(new_source, new_path)
        match = self._find_by_hash(sub.semantic, new_constructs)

        if match:
            # Found by hash - it was renamed/moved
            trigger = self._classify_semantic_change(sub, old_construct, match)
            proposal = Proposal(
                subscription_id=sub.id,
                subscription=sub,
                old_path=old_path,
                old_start=sub.start_line,
                old_end=sub.end_line,
                new_path=new_path,
                new_start=match.start_line,
                new_end=match.end_line,
                reasons=["semantic_location"],
                confidence="high",
                new_qualname=match.qualname,
                new_kind=match.kind,
            )
            return trigger, proposal

        # Not found at all
        return (
            Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=old_path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=["semantic_target_missing"],
                matching_hunks=[],
                change_type="MISSING",
            ),
            None,
        )

    def _classify_semantic_change(
        self,
        sub: Subscription,
        old_construct: "Construct | None",
        new_construct: "Construct",
    ) -> Trigger | None:
        """Classify change type between old and new construct."""
        if old_construct is None or sub.semantic is None:
            return None

        old_fp = sub.semantic

        # Check interface change (type/signature)
        if old_fp.interface_hash != new_construct.interface_hash:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=["interface_changed"],
                matching_hunks=[],
                change_type="STRUCTURAL",
            )

        # Check body change (value/implementation)
        if old_fp.body_hash != new_construct.body_hash:
            return Trigger(
                subscription_id=sub.id,
                subscription=sub,
                path=sub.path,
                start_line=sub.start_line,
                end_line=sub.end_line,
                reasons=["body_changed"],
                matching_hunks=[],
                change_type="CONTENT",
            )

        # No meaningful change (cosmetic only)
        return None

    def _find_by_hash(
        self,
        semantic: SemanticTarget,
        constructs: "list[Construct]",
    ) -> "Construct | None":
        """Find construct by hash matching."""
        # Try exact match (both hashes)
        matches = [
            c
            for c in constructs
            if c.interface_hash == semantic.interface_hash
            and c.body_hash == semantic.body_hash
            and c.kind == semantic.kind
        ]
        if len(matches) == 1:
            return matches[0]

        # Try body-only match (renamed + signature changed)
        matches = [
            c
            for c in constructs
            if c.body_hash == semantic.body_hash and c.kind == semantic.kind
        ]
        if len(matches) == 1:
            return matches[0]

        # Try interface-only match (renamed + body changed)
        matches = [
            c
            for c in constructs
            if c.interface_hash == semantic.interface_hash and c.kind == semantic.kind
        ]
        if len(matches) == 1:
            return matches[0]

        return None
</file>

<file path="src/codesub/models.py">
"""Data models for codesub."""

from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any
import uuid


def _utc_now() -> str:
    """Return current UTC time as ISO 8601 string."""
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")


def _generate_id() -> str:
    """Generate a new subscription ID."""
    return str(uuid.uuid4())


@dataclass
class SemanticTarget:
    """Semantic identifier for a code construct."""

    language: str  # "python"
    kind: str  # "variable"|"field"|"method"
    qualname: str  # "MAX_RETRIES" | "User.role" | "User.save"
    role: str | None = None  # "const" for constants, else None
    interface_hash: str = ""
    body_hash: str = ""
    fingerprint_version: int = 1

    def to_dict(self) -> dict[str, Any]:
        return {
            "language": self.language,
            "kind": self.kind,
            "qualname": self.qualname,
            "role": self.role,
            "interface_hash": self.interface_hash,
            "body_hash": self.body_hash,
            "fingerprint_version": self.fingerprint_version,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "SemanticTarget":
        return cls(
            language=data["language"],
            kind=data["kind"],
            qualname=data["qualname"],
            role=data.get("role"),
            interface_hash=data.get("interface_hash", ""),
            body_hash=data.get("body_hash", ""),
            fingerprint_version=data.get("fingerprint_version", 1),
        )


@dataclass
class Anchor:
    """Context lines around a subscription for display and future fuzzy matching."""

    context_before: list[str]
    lines: list[str]
    context_after: list[str]

    def to_dict(self) -> dict[str, Any]:
        return {
            "context_before": self.context_before,
            "lines": self.lines,
            "context_after": self.context_after,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Anchor":
        return cls(
            context_before=data.get("context_before", []),
            lines=data.get("lines", []),
            context_after=data.get("context_after", []),
        )


@dataclass
class Subscription:
    """A subscription to a file line range."""

    id: str
    path: str  # repo-relative, POSIX-style
    start_line: int  # 1-based inclusive
    end_line: int  # 1-based inclusive
    label: str | None = None
    description: str | None = None
    anchors: Anchor | None = None
    semantic: SemanticTarget | None = None
    active: bool = True
    created_at: str = field(default_factory=_utc_now)
    updated_at: str = field(default_factory=_utc_now)

    def to_dict(self) -> dict[str, Any]:
        result: dict[str, Any] = {
            "id": self.id,
            "path": self.path,
            "start_line": self.start_line,
            "end_line": self.end_line,
            "active": self.active,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
        }
        if self.label is not None:
            result["label"] = self.label
        if self.description is not None:
            result["description"] = self.description
        if self.anchors is not None:
            result["anchors"] = self.anchors.to_dict()
        if self.semantic is not None:
            result["semantic"] = self.semantic.to_dict()
        return result

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Subscription":
        anchors = None
        if "anchors" in data:
            anchors = Anchor.from_dict(data["anchors"])
        semantic = None
        if "semantic" in data:
            semantic = SemanticTarget.from_dict(data["semantic"])
        return cls(
            id=data["id"],
            path=data["path"],
            start_line=data["start_line"],
            end_line=data["end_line"],
            label=data.get("label"),
            description=data.get("description"),
            anchors=anchors,
            semantic=semantic,
            active=data.get("active", True),
            created_at=data.get("created_at", ""),
            updated_at=data.get("updated_at", ""),
        )

    @classmethod
    def create(
        cls,
        path: str,
        start_line: int,
        end_line: int,
        label: str | None = None,
        description: str | None = None,
        anchors: Anchor | None = None,
        semantic: "SemanticTarget | None" = None,
    ) -> "Subscription":
        """Create a new subscription with generated ID and timestamps."""
        now = _utc_now()
        return cls(
            id=_generate_id(),
            path=path,
            start_line=start_line,
            end_line=end_line,
            label=label,
            description=description,
            anchors=anchors,
            semantic=semantic,
            active=True,
            created_at=now,
            updated_at=now,
        )


@dataclass
class RepoConfig:
    """Repository-level configuration."""

    baseline_ref: str
    created_at: str = field(default_factory=_utc_now)
    updated_at: str = field(default_factory=_utc_now)

    def to_dict(self) -> dict[str, Any]:
        return {
            "baseline_ref": self.baseline_ref,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "RepoConfig":
        return cls(
            baseline_ref=data["baseline_ref"],
            created_at=data.get("created_at", ""),
            updated_at=data.get("updated_at", ""),
        )


@dataclass
class Config:
    """Full configuration containing repo config and subscriptions."""

    schema_version: int
    repo: RepoConfig
    subscriptions: list[Subscription]

    def to_dict(self) -> dict[str, Any]:
        return {
            "schema_version": self.schema_version,
            "repo": self.repo.to_dict(),
            "subscriptions": [s.to_dict() for s in self.subscriptions],
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Config":
        return cls(
            schema_version=data["schema_version"],
            repo=RepoConfig.from_dict(data["repo"]),
            subscriptions=[Subscription.from_dict(s) for s in data.get("subscriptions", [])],
        )

    @classmethod
    def create(cls, baseline_ref: str) -> "Config":
        """Create a new config with the given baseline ref."""
        return cls(
            schema_version=1,
            repo=RepoConfig(baseline_ref=baseline_ref),
            subscriptions=[],
        )


# Models for diff parsing


@dataclass
class Hunk:
    """A single hunk from a unified diff."""

    old_start: int
    old_count: int
    new_start: int
    new_count: int


@dataclass
class FileDiff:
    """Diff information for a single file."""

    old_path: str
    new_path: str
    hunks: list[Hunk]
    is_rename: bool = False
    is_new_file: bool = False
    is_deleted_file: bool = False


# Models for detection results


@dataclass
class Trigger:
    """A subscription that was triggered by changes."""

    subscription_id: str
    subscription: Subscription
    path: str
    start_line: int
    end_line: int
    reasons: list[str]  # e.g., ["overlap_hunk", "file_deleted", "insert_inside_range"]
    matching_hunks: list[Hunk]
    change_type: str | None = None  # "STRUCTURAL"|"CONTENT"|"MISSING"|"AMBIGUOUS"|"PARSE_ERROR"
    details: dict[str, Any] | None = None


@dataclass
class Proposal:
    """A proposed update to a subscription (rename or line shift)."""

    subscription_id: str
    subscription: Subscription
    old_path: str
    old_start: int
    old_end: int
    new_path: str
    new_start: int
    new_end: int
    reasons: list[str]  # ["rename", "line_shift", "semantic_location"]
    confidence: str = "high"  # "high" for POC (math-based)
    shift: int | None = None
    new_qualname: str | None = None  # For semantic subscriptions when construct renamed
    new_kind: str | None = None  # For semantic subscriptions if kind changed


@dataclass
class ScanResult:
    """Result of scanning for changes."""

    base_ref: str
    target_ref: str
    triggers: list[Trigger]
    proposals: list[Proposal]
    unchanged: list[Subscription]  # Subscriptions with no changes or shifts


# Models for multi-project management


@dataclass
class Project:
    """A registered project (git repository with codesub initialized)."""

    id: str
    name: str  # Display name (defaults to repo directory name)
    path: str  # Absolute path to the repository root
    created_at: str = field(default_factory=_utc_now)
    updated_at: str = field(default_factory=_utc_now)

    def to_dict(self) -> dict[str, Any]:
        return {
            "id": self.id,
            "name": self.name,
            "path": self.path,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Project":
        return cls(
            id=data["id"],
            name=data["name"],
            path=data["path"],
            created_at=data.get("created_at", ""),
            updated_at=data.get("updated_at", ""),
        )

    @classmethod
    def create(cls, name: str, path: str) -> "Project":
        """Create a new project with generated ID and timestamps."""
        now = _utc_now()
        return cls(
            id=_generate_id(),
            name=name,
            path=path,
            created_at=now,
            updated_at=now,
        )


@dataclass
class ScanHistoryEntry:
    """A persisted scan result."""

    id: str
    project_id: str
    base_ref: str
    target_ref: str
    trigger_count: int
    proposal_count: int
    unchanged_count: int
    created_at: str
    scan_result: dict[str, Any]  # Full ScanResult as dict

    def to_dict(self) -> dict[str, Any]:
        return {
            "id": self.id,
            "project_id": self.project_id,
            "base_ref": self.base_ref,
            "target_ref": self.target_ref,
            "trigger_count": self.trigger_count,
            "proposal_count": self.proposal_count,
            "unchanged_count": self.unchanged_count,
            "created_at": self.created_at,
            "scan_result": self.scan_result,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "ScanHistoryEntry":
        return cls(
            id=data["id"],
            project_id=data["project_id"],
            base_ref=data["base_ref"],
            target_ref=data["target_ref"],
            trigger_count=data["trigger_count"],
            proposal_count=data["proposal_count"],
            unchanged_count=data["unchanged_count"],
            created_at=data["created_at"],
            scan_result=data["scan_result"],
        )
</file>

<file path="pyproject.toml">
[tool.poetry]
name = "codesub"
version = "0.1.0"
description = "Subscribe to file line ranges and detect changes via git diff"
authors = ["Developer"]
license = "MIT"
readme = "README.md"
packages = [{include = "codesub", from = "src"}]

[tool.poetry.dependencies]
python = ">=3.10"
fastapi = ">=0.109.0"
uvicorn = {version = ">=0.27.0", extras = ["standard"]}
tree-sitter = ">=0.21.0"
tree-sitter-python = ">=0.21.0"

[tool.poetry.group.dev.dependencies]
pytest = ">=7.0"
pytest-cov = ">=4.0"
httpx = ">=0.26.0"

[tool.poetry.scripts]
codesub = "codesub.cli:main"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
</file>

<file path="src/codesub/api.py">
"""FastAPI REST API for codesub subscription management."""

from pathlib import Path
from fastapi import FastAPI, HTTPException, Query, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import Optional

from .config_store import ConfigStore
from .errors import (
    CodesubError,
    ConfigNotFoundError,
    SubscriptionNotFoundError,
    InvalidLocationError,
    InvalidLineRangeError,
    FileNotFoundAtRefError,
    InvalidSchemaVersionError,
    NotAGitRepoError,
    GitError,
    ProjectNotFoundError,
    InvalidProjectPathError,
    ScanNotFoundError,
)
from .git_repo import GitRepo
from .models import Anchor, Subscription, SemanticTarget
from .utils import parse_location, extract_anchors, parse_target_spec, LineTarget, SemanticTargetSpec
from .project_store import ProjectStore
from .scan_history import ScanHistory
from .detector import Detector
from .updater import Updater
from .update_doc import result_to_dict


# --- Pydantic Schemas ---


class AnchorSchema(BaseModel):
    context_before: list[str]
    lines: list[str]
    context_after: list[str]


class SemanticTargetSchema(BaseModel):
    """Schema for semantic subscription target."""

    language: str  # "python"
    kind: str  # "variable"|"field"|"method"
    qualname: str  # "API_VERSION" | "User.role" | "Calculator.add"
    role: Optional[str] = None  # "const" for constants, None otherwise
    interface_hash: str = ""
    body_hash: str = ""
    fingerprint_version: int = 1


class SubscriptionSchema(BaseModel):
    id: str
    path: str
    start_line: int
    end_line: int
    label: Optional[str] = None
    description: Optional[str] = None
    anchors: Optional[AnchorSchema] = None
    semantic: Optional[SemanticTargetSchema] = None
    active: bool = True
    created_at: str
    updated_at: str


class SubscriptionCreateRequest(BaseModel):
    """Request body for creating a subscription."""

    location: str = Field(
        ...,
        description="Location format: 'path:line' or 'path:start-end' for line-based, "
        "'path::QualName' or 'path::kind:QualName' for semantic",
    )
    label: Optional[str] = None
    description: Optional[str] = None
    context: int = Field(default=2, ge=0, le=10)


class SubscriptionUpdateRequest(BaseModel):
    """Request body for updating a subscription."""

    label: Optional[str] = None
    description: Optional[str] = None


class SubscriptionListResponse(BaseModel):
    subscriptions: list[SubscriptionSchema]
    count: int
    baseline_ref: str
    baseline_title: str = ""


class ErrorResponse(BaseModel):
    detail: str
    error_type: str


# --- Project Schemas ---


class ProjectSchema(BaseModel):
    id: str
    name: str
    path: str
    created_at: str
    updated_at: str


class ProjectCreateRequest(BaseModel):
    path: str = Field(..., description="Absolute path to git repository")
    name: Optional[str] = Field(None, description="Display name (defaults to dir name)")


class ProjectUpdateRequest(BaseModel):
    name: str = Field(..., description="New display name")


class ProjectListResponse(BaseModel):
    projects: list[ProjectSchema]
    count: int


class ProjectStatusResponse(BaseModel):
    project: ProjectSchema
    path_exists: bool
    codesub_initialized: bool
    subscription_count: int
    baseline_ref: Optional[str]


# --- Scan Schemas ---


class ScanRequest(BaseModel):
    base_ref: str = Field(..., description="Base git ref (e.g., 'HEAD~1', 'baseline', commit hash)")
    target_ref: Optional[str] = Field(default="HEAD", description="Target git ref ('HEAD', commit hash), or empty/null for working directory")


class TriggerSchema(BaseModel):
    subscription_id: str
    path: str
    start_line: int
    end_line: int
    reasons: list[str]
    label: Optional[str]
    change_type: Optional[str] = None  # "STRUCTURAL"|"CONTENT"|"MISSING" for semantic subscriptions
    details: Optional[dict] = None  # Additional details for semantic triggers


class ProposalSchema(BaseModel):
    subscription_id: str
    old_path: str
    old_start: int
    old_end: int
    new_path: str
    new_start: int
    new_end: int
    reasons: list[str]
    confidence: str
    shift: Optional[int]
    label: Optional[str]
    new_qualname: Optional[str] = None  # For semantic subscriptions when construct renamed
    new_kind: Optional[str] = None  # For semantic subscriptions if kind changed


class ScanResultSchema(BaseModel):
    base_ref: str
    target_ref: str
    triggers: list[TriggerSchema]
    proposals: list[ProposalSchema]
    unchanged_count: int


class ScanHistoryEntrySchema(BaseModel):
    id: str
    project_id: str
    base_ref: str
    target_ref: str
    trigger_count: int
    proposal_count: int
    unchanged_count: int
    created_at: str


class ScanHistoryListResponse(BaseModel):
    scans: list[ScanHistoryEntrySchema]
    count: int


class ApplyUpdatesRequest(BaseModel):
    scan_id: str = Field(..., description="Scan ID to apply proposals from")
    proposal_ids: Optional[list[str]] = Field(
        None,
        description="Specific proposal IDs to apply (all if not specified)"
    )


class ApplyUpdatesResponse(BaseModel):
    applied: list[str]
    warnings: list[str]
    new_baseline: Optional[str]


# --- Filesystem Browser Schemas ---


class FilesystemEntry(BaseModel):
    name: str
    path: str
    is_dir: bool


class FilesystemBrowseResponse(BaseModel):
    current_path: str
    parent_path: Optional[str]
    entries: list[FilesystemEntry]


# --- Helper Functions ---


def get_project_store() -> ProjectStore:
    """Get the global ProjectStore."""
    return ProjectStore()


def get_scan_history() -> ScanHistory:
    """Get the global ScanHistory."""
    return ScanHistory()


def get_project_store_and_repo(project_id: str) -> tuple[ConfigStore, GitRepo]:
    """Get ConfigStore and GitRepo for a specific project."""
    project_store = get_project_store()
    project = project_store.get_project(project_id)

    repo = GitRepo(project.path)
    store = ConfigStore(repo.root)
    return store, repo


def get_store_and_repo() -> tuple[ConfigStore, GitRepo]:
    """Get ConfigStore and GitRepo for the current directory."""
    repo = GitRepo()
    store = ConfigStore(repo.root)
    return store, repo


def subscription_to_schema(sub: Subscription) -> SubscriptionSchema:
    """Convert dataclass Subscription to Pydantic schema."""
    anchors = None
    if sub.anchors:
        anchors = AnchorSchema(
            context_before=sub.anchors.context_before,
            lines=sub.anchors.lines,
            context_after=sub.anchors.context_after,
        )
    semantic = None
    if sub.semantic:
        semantic = SemanticTargetSchema(
            language=sub.semantic.language,
            kind=sub.semantic.kind,
            qualname=sub.semantic.qualname,
            role=sub.semantic.role,
            interface_hash=sub.semantic.interface_hash,
            body_hash=sub.semantic.body_hash,
            fingerprint_version=sub.semantic.fingerprint_version,
        )
    return SubscriptionSchema(
        id=sub.id,
        path=sub.path,
        start_line=sub.start_line,
        end_line=sub.end_line,
        label=sub.label,
        description=sub.description,
        anchors=anchors,
        semantic=semantic,
        active=sub.active,
        created_at=sub.created_at,
        updated_at=sub.updated_at,
    )


def _create_subscription_from_request(
    store: ConfigStore,
    repo: GitRepo,
    baseline: str,
    request: SubscriptionCreateRequest,
) -> Subscription:
    """Create a subscription from a request, handling both line-based and semantic targets."""
    from .semantic import PythonIndexer

    target = parse_target_spec(request.location)

    if isinstance(target, SemanticTargetSpec):
        # Semantic subscription
        lines = repo.show_file(baseline, target.path)
        source = "\n".join(lines)

        indexer = PythonIndexer()
        construct = indexer.find_construct(
            source, target.path, target.qualname, target.kind
        )
        if construct is None:
            raise InvalidLocationError(
                request.location,
                f"Construct '{target.qualname}' not found. Use 'codesub symbols' to discover valid targets.",
            )

        # Extract anchors from construct lines
        context_before, watched_lines, context_after = extract_anchors(
            lines, construct.start_line, construct.end_line, context=request.context
        )
        anchors = Anchor(
            context_before=context_before,
            lines=watched_lines,
            context_after=context_after,
        )

        # Create semantic target
        semantic = SemanticTarget(
            language="python",
            kind=construct.kind,
            qualname=construct.qualname,
            role=construct.role,
            interface_hash=construct.interface_hash,
            body_hash=construct.body_hash,
        )

        return Subscription.create(
            path=target.path,
            start_line=construct.start_line,
            end_line=construct.end_line,
            label=request.label,
            description=request.description,
            anchors=anchors,
            semantic=semantic,
        )
    else:
        # Line-based subscription
        lines = repo.show_file(baseline, target.path)

        # Validate line range
        if target.end_line > len(lines):
            raise InvalidLineRangeError(
                target.start_line,
                target.end_line,
                f"exceeds file length ({len(lines)} lines)",
            )

        # Extract anchors
        context_before, watched_lines, context_after = extract_anchors(
            lines, target.start_line, target.end_line, context=request.context
        )
        anchors = Anchor(
            context_before=context_before,
            lines=watched_lines,
            context_after=context_after,
        )

        return Subscription.create(
            path=target.path,
            start_line=target.start_line,
            end_line=target.end_line,
            label=request.label,
            description=request.description,
            anchors=anchors,
        )


# --- FastAPI App ---


app = FastAPI(
    title="codesub API",
    description="REST API for managing code subscriptions",
    version="0.1.0",
)

# CORS for local development
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- Global Exception Handler ---


# Map exception types to HTTP status codes
ERROR_STATUS_CODES: dict[type, int] = {
    ConfigNotFoundError: 409,
    SubscriptionNotFoundError: 404,
    InvalidLocationError: 400,
    InvalidLineRangeError: 400,
    FileNotFoundAtRefError: 404,
    InvalidSchemaVersionError: 500,
    NotAGitRepoError: 500,
    GitError: 500,
    ProjectNotFoundError: 404,
    InvalidProjectPathError: 400,
    ScanNotFoundError: 404,
}


@app.exception_handler(CodesubError)
async def codesub_error_handler(request: Request, exc: CodesubError) -> JSONResponse:
    """Map CodesubError subclasses to appropriate HTTP responses."""
    status_code = ERROR_STATUS_CODES.get(type(exc), 500)
    return JSONResponse(
        status_code=status_code,
        content={"detail": str(exc), "error_type": type(exc).__name__},
    )


# --- Endpoints ---


@app.get("/api/subscriptions", response_model=SubscriptionListResponse)
def list_subscriptions(include_inactive: bool = Query(default=False)):
    """List all subscriptions, optionally including inactive ones."""
    store, repo = get_store_and_repo()
    config = store.load()
    subs = store.list_subscriptions(include_inactive=include_inactive)
    baseline_title = repo.commit_title(config.repo.baseline_ref) if config.repo.baseline_ref else ""
    return SubscriptionListResponse(
        subscriptions=[subscription_to_schema(s) for s in subs],
        count=len(subs),
        baseline_ref=config.repo.baseline_ref,
        baseline_title=baseline_title,
    )


@app.get("/api/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def get_subscription(sub_id: str):
    """Get a single subscription by ID (supports partial ID matching)."""
    store, _ = get_store_and_repo()
    sub = store.get_subscription(sub_id)
    return subscription_to_schema(sub)


@app.post("/api/subscriptions", response_model=SubscriptionSchema, status_code=201)
def create_subscription(request: SubscriptionCreateRequest):
    """Create a new subscription (line-based or semantic)."""
    store, repo = get_store_and_repo()
    config = store.load()
    baseline = config.repo.baseline_ref

    sub = _create_subscription_from_request(store, repo, baseline, request)
    store.add_subscription(sub)
    return subscription_to_schema(sub)


@app.patch("/api/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def update_subscription(sub_id: str, request: SubscriptionUpdateRequest):
    """Update subscription label and/or description.

    PATCH semantics:
    - Omitted field: keep existing value
    - Empty string "": clear to null
    - Explicit null: clear to null
    """
    store, _ = get_store_and_repo()
    sub = store.get_subscription(sub_id)

    # Get the fields that were actually sent in the request
    update_data = request.model_dump(exclude_unset=True)

    # Update fields if provided
    if "label" in update_data:
        # Empty string becomes None
        sub.label = request.label if request.label else None
    if "description" in update_data:
        # Empty string becomes None
        sub.description = request.description if request.description else None

    store.update_subscription(sub)
    return subscription_to_schema(sub)


@app.delete("/api/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def delete_subscription(sub_id: str, hard: bool = Query(default=False)):
    """Delete (deactivate or hard delete) a subscription."""
    store, _ = get_store_and_repo()
    sub = store.remove_subscription(sub_id, hard=hard)
    return subscription_to_schema(sub)


@app.post("/api/subscriptions/{sub_id}/reactivate", response_model=SubscriptionSchema)
def reactivate_subscription(sub_id: str):
    """Reactivate a deactivated subscription."""
    store, _ = get_store_and_repo()
    sub = store.get_subscription(sub_id)

    if sub.active:
        raise HTTPException(status_code=400, detail="Subscription is already active")

    sub.active = True
    store.update_subscription(sub)
    return subscription_to_schema(sub)


@app.get("/api/health")
def health_check():
    """Health check endpoint. Always returns 200."""
    try:
        store, repo = get_store_and_repo()
        config_exists = store.exists()
        baseline_ref = None
        if config_exists:
            config = store.load()
            baseline_ref = config.repo.baseline_ref
        return {
            "status": "ok",
            "config_initialized": config_exists,
            "repo_root": str(repo.root),
            "baseline_ref": baseline_ref,
        }
    except NotAGitRepoError:
        return {
            "status": "error",
            "config_initialized": False,
            "detail": "Not running in a git repository",
        }
    except Exception as e:
        return {
            "status": "error",
            "config_initialized": False,
            "detail": str(e),
        }


# --- Project Endpoints ---


@app.get("/api/projects", response_model=ProjectListResponse)
def list_projects():
    """List all registered projects."""
    store = get_project_store()
    projects = store.list_projects()
    return ProjectListResponse(
        projects=[ProjectSchema(**p.to_dict()) for p in projects],
        count=len(projects),
    )


@app.post("/api/projects", response_model=ProjectSchema, status_code=201)
def create_project(request: ProjectCreateRequest):
    """Register a new project."""
    store = get_project_store()
    project = store.add_project(path=request.path, name=request.name)
    return ProjectSchema(**project.to_dict())


@app.get("/api/projects/{project_id}", response_model=ProjectStatusResponse)
def get_project_status(project_id: str):
    """Get project details and status."""
    store = get_project_store()
    status = store.get_project_status(project_id)
    return ProjectStatusResponse(
        project=ProjectSchema(**status["project"]),
        path_exists=status["path_exists"],
        codesub_initialized=status["codesub_initialized"],
        subscription_count=status["subscription_count"],
        baseline_ref=status["baseline_ref"],
    )


@app.patch("/api/projects/{project_id}", response_model=ProjectSchema)
def update_project(project_id: str, request: ProjectUpdateRequest):
    """Update project name."""
    store = get_project_store()
    project = store.update_project(project_id, request.name)
    return ProjectSchema(**project.to_dict())


@app.delete("/api/projects/{project_id}", response_model=ProjectSchema)
def delete_project(project_id: str):
    """Remove a project from the registry."""
    store = get_project_store()
    project = store.remove_project(project_id)
    return ProjectSchema(**project.to_dict())


# --- Project Subscriptions Endpoints ---


@app.get("/api/projects/{project_id}/subscriptions", response_model=SubscriptionListResponse)
def list_project_subscriptions(
    project_id: str,
    include_inactive: bool = Query(default=False)
):
    """List subscriptions for a specific project."""
    store, repo = get_project_store_and_repo(project_id)
    config = store.load()
    subs = store.list_subscriptions(include_inactive=include_inactive)
    baseline_title = repo.commit_title(config.repo.baseline_ref) if config.repo.baseline_ref else ""
    return SubscriptionListResponse(
        subscriptions=[subscription_to_schema(s) for s in subs],
        count=len(subs),
        baseline_ref=config.repo.baseline_ref,
        baseline_title=baseline_title,
    )


@app.post("/api/projects/{project_id}/subscriptions", response_model=SubscriptionSchema, status_code=201)
def create_project_subscription(project_id: str, request: SubscriptionCreateRequest):
    """Create a new subscription in a specific project (line-based or semantic)."""
    store, repo = get_project_store_and_repo(project_id)
    config = store.load()
    baseline = config.repo.baseline_ref

    sub = _create_subscription_from_request(store, repo, baseline, request)
    store.add_subscription(sub)
    return subscription_to_schema(sub)


@app.get("/api/projects/{project_id}/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def get_project_subscription(project_id: str, sub_id: str):
    """Get a single subscription by ID within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.get_subscription(sub_id)
    return subscription_to_schema(sub)


@app.patch("/api/projects/{project_id}/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def update_project_subscription(project_id: str, sub_id: str, request: SubscriptionUpdateRequest):
    """Update subscription label and/or description within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.get_subscription(sub_id)

    update_data = request.model_dump(exclude_unset=True)

    if "label" in update_data:
        sub.label = request.label if request.label else None
    if "description" in update_data:
        sub.description = request.description if request.description else None

    store.update_subscription(sub)
    return subscription_to_schema(sub)


@app.delete("/api/projects/{project_id}/subscriptions/{sub_id}", response_model=SubscriptionSchema)
def delete_project_subscription(project_id: str, sub_id: str, hard: bool = Query(default=False)):
    """Delete (deactivate or hard delete) a subscription within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.remove_subscription(sub_id, hard=hard)
    return subscription_to_schema(sub)


@app.post("/api/projects/{project_id}/subscriptions/{sub_id}/reactivate", response_model=SubscriptionSchema)
def reactivate_project_subscription(project_id: str, sub_id: str):
    """Reactivate a deactivated subscription within a project."""
    store, _ = get_project_store_and_repo(project_id)
    sub = store.get_subscription(sub_id)

    if sub.active:
        raise HTTPException(status_code=400, detail="Subscription is already active")

    sub.active = True
    store.update_subscription(sub)
    return subscription_to_schema(sub)


# --- Scan Endpoints ---


@app.post("/api/projects/{project_id}/scan", response_model=ScanHistoryEntrySchema)
def run_project_scan(project_id: str, request: ScanRequest):
    """
    Run a scan for a project and save to history.

    Special ref values:
    - "baseline": Use project's configured baseline ref
    - "HEAD~N": N commits back from HEAD
    """
    store, repo = get_project_store_and_repo(project_id)
    config = store.load()

    # Resolve refs
    base_ref = request.base_ref
    target_ref = request.target_ref

    # Handle special values
    if base_ref == "baseline":
        base_ref = config.repo.baseline_ref

    # Resolve to commit hashes (empty target_ref means working directory)
    base_ref = repo.resolve_ref(base_ref)
    if target_ref:
        target_ref = repo.resolve_ref(target_ref)
    else:
        target_ref = None  # Working directory

    # Run scan
    detector = Detector(repo)
    result = detector.scan(config.subscriptions, base_ref, target_ref)

    # Convert to dict and save to history
    result_dict = result_to_dict(result)
    history = get_scan_history()
    entry = history.save_scan(project_id, result_dict)

    return ScanHistoryEntrySchema(
        id=entry.id,
        project_id=entry.project_id,
        base_ref=entry.base_ref,
        target_ref=entry.target_ref,
        trigger_count=entry.trigger_count,
        proposal_count=entry.proposal_count,
        unchanged_count=entry.unchanged_count,
        created_at=entry.created_at,
    )


@app.get("/api/projects/{project_id}/scan-history", response_model=ScanHistoryListResponse)
def list_scan_history(
    project_id: str,
    limit: int = Query(default=50, ge=1, le=100)
):
    """List scan history for a project."""
    # Validate project exists
    project_store = get_project_store()
    _ = project_store.get_project(project_id)

    history = get_scan_history()
    entries = history.list_scans(project_id, limit=limit)

    return ScanHistoryListResponse(
        scans=[
            ScanHistoryEntrySchema(
                id=e.id,
                project_id=e.project_id,
                base_ref=e.base_ref,
                target_ref=e.target_ref,
                trigger_count=e.trigger_count,
                proposal_count=e.proposal_count,
                unchanged_count=e.unchanged_count,
                created_at=e.created_at,
            )
            for e in entries
        ],
        count=len(entries),
    )


@app.get("/api/projects/{project_id}/scan-history/{scan_id}")
def get_scan_result(project_id: str, scan_id: str):
    """Get a specific scan result with full details."""
    # Validate project exists
    project_store = get_project_store()
    _ = project_store.get_project(project_id)

    history = get_scan_history()
    entry = history.get_scan(project_id, scan_id)

    return entry.to_dict()


@app.delete("/api/projects/{project_id}/scan-history")
def clear_project_scan_history(project_id: str):
    """Clear all scan history for a project."""
    # Validate project exists
    project_store = get_project_store()
    _ = project_store.get_project(project_id)

    history = get_scan_history()
    count = history.clear_project_history(project_id)

    return {"deleted": count}


@app.delete("/api/scan-history")
def clear_all_scan_history():
    """Clear all scan history for all projects."""
    history = get_scan_history()
    count = history.clear_all_history()

    return {"deleted": count}


# --- Apply Updates Endpoint ---


@app.post("/api/projects/{project_id}/apply-updates", response_model=ApplyUpdatesResponse)
def apply_project_updates(project_id: str, request: ApplyUpdatesRequest):
    """
    Apply proposals from a scan result.

    Updates subscriptions and advances baseline to the scan's target_ref.
    """
    store, repo = get_project_store_and_repo(project_id)

    # Get the scan result
    history = get_scan_history()
    entry = history.get_scan(project_id, request.scan_id)
    scan_result = entry.scan_result

    # Filter proposals if specific IDs requested
    proposals = scan_result.get("proposals", [])
    if request.proposal_ids:
        proposals = [p for p in proposals if p["subscription_id"] in request.proposal_ids]

    # Build update document format
    update_data = {
        "target_ref": scan_result.get("target_ref", ""),
        "proposals": proposals,
    }

    # Apply updates
    updater = Updater(store, repo)
    applied, warnings = updater.apply(update_data)

    return ApplyUpdatesResponse(
        applied=applied,
        warnings=warnings,
        new_baseline=scan_result.get("target_ref") if applied else None,
    )


# --- Filesystem Browser Endpoint ---


@app.get("/api/filesystem/browse", response_model=FilesystemBrowseResponse)
def browse_filesystem(path: str = Query(default="~", description="Path to browse")):
    """
    Browse filesystem directories.

    Used by the frontend to provide a file picker for selecting project paths.
    Returns directories (not files) sorted alphabetically, with hidden dirs excluded.
    Restricted to user's home directory for security.
    """
    home = Path.home().resolve()

    # Expand ~ and resolve path
    try:
        expanded = Path(path).expanduser().resolve()
    except Exception:
        raise HTTPException(status_code=400, detail=f"Invalid path: {path}")

    # Security: restrict to home directory
    try:
        expanded.relative_to(home)
    except ValueError:
        raise HTTPException(
            status_code=403,
            detail=f"Access restricted to home directory ({home})"
        )

    if not expanded.exists():
        raise HTTPException(status_code=404, detail=f"Path not found: {path}")

    if not expanded.is_dir():
        raise HTTPException(status_code=400, detail=f"Not a directory: {path}")

    # Get parent path (None if at home directory)
    if expanded == home:
        parent_path = None
    else:
        parent = expanded.parent
        # Ensure parent is still within home
        try:
            parent.relative_to(home)
            parent_path = str(parent)
        except ValueError:
            parent_path = None

    # List directory entries (directories only, exclude hidden)
    entries: list[FilesystemEntry] = []
    try:
        for item in sorted(expanded.iterdir(), key=lambda p: p.name.lower()):
            try:
                # Skip hidden directories
                if item.name.startswith("."):
                    continue
                # Skip symlinks to avoid escaping home directory
                if item.is_symlink():
                    continue
                if item.is_dir():
                    entries.append(
                        FilesystemEntry(
                            name=item.name,
                            path=str(item),
                            is_dir=True,
                        )
                    )
            except OSError:
                # Skip entries that can't be inspected (broken symlinks, etc.)
                continue
    except PermissionError:
        raise HTTPException(status_code=403, detail=f"Permission denied: {path}")

    return FilesystemBrowseResponse(
        current_path=str(expanded),
        parent_path=parent_path,
        entries=entries,
    )
</file>

</files>
